diff --git a/.gitignore b/.gitignore
index 0bab26c..38ce622 100644
--- a/.gitignore
+++ b/.gitignore
@@ -11,10 +11,13 @@ example/.flutter-plugins
 example/android/local.properties
 .dart_tool/package_config.json
 android/.project
+android/libs/*
+!android/libs/readme.txt
 example/ios/Runner/GeneratedPluginRegistrant.m
 example/ios/Runner/GeneratedPluginRegistrant.h
 example/ios/Flutter/Generated.xcconfig
 example/ios/Flutter/flutter_export_environment.sh
+flutter-webrtc-*.patch
 
 # Miscellaneous
 *.class
diff --git a/android/build.gradle b/android/build.gradle
index f9b288f..e3a4287 100644
--- a/android/build.gradle
+++ b/android/build.gradle
@@ -53,6 +53,7 @@ android {
 
 dependencies {
     implementation 'io.github.webrtc-sdk:android:125.6422.03'
+    implementation(files("libs/Effects_SDK_v.2.11.4.aar"))
     implementation 'com.github.davidliu:audioswitch:89582c47c9a04c62f90aa5e57251af4800a62c9a'
     implementation 'androidx.annotation:annotation:1.1.0'
     implementation "org.jetbrains.kotlin:kotlin-stdlib-jdk7:$kotlin_version"
diff --git a/android/libs/readme.txt b/android/libs/readme.txt
new file mode 100644
index 0000000..ca50f49
--- /dev/null
+++ b/android/libs/readme.txt
@@ -0,0 +1 @@
+Place Effects SDK lib here
diff --git a/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java b/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java
index 0b0998f..5a67944 100755
--- a/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java
+++ b/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java
@@ -9,6 +9,7 @@ import android.content.ContentValues;
 import android.content.Context;
 import android.content.Intent;
 import android.content.pm.PackageManager;
+import android.graphics.Bitmap;
 import android.graphics.Point;
 import android.hardware.camera2.CameraManager;
 import android.media.AudioDeviceInfo;
@@ -49,6 +50,8 @@ import com.cloudwebrtc.webrtc.utils.ObjectType;
 import com.cloudwebrtc.webrtc.utils.PermissionUtils;
 import com.cloudwebrtc.webrtc.video.LocalVideoTrack;
 import com.cloudwebrtc.webrtc.video.VideoCapturerInfo;
+import com.cloudwebrtc.webrtc.video.camera.EffectsSDKVideoCapturer;
+import com.effectssdk.tsvb.EffectsSDKStatus;
 
 import org.webrtc.AudioSource;
 import org.webrtc.AudioTrack;
@@ -163,6 +166,144 @@ public class GetUserMediaImpl {
                 });
     }
 
+    public void setEffectsSdkBlurPower(String trackId, double blurPower) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setBlurPower((float) blurPower);
+        }
+    }
+
+    public EffectsSDKStatus initializeEffectsSdk(String trackId, String customerId, String url) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            return capturer.initializeEffectsSdk(customerId, url);
+        }
+        return EffectsSDKStatus.INACTIVE;
+    }
+
+    public void enableEffectsSdkVideoStream(String trackId, boolean enabled) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.enableVideo(enabled);
+        }
+    }
+
+    public EffectsSDKStatus initializeEffectsSdkLocal(String trackId, String localKey) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            return capturer.initializeEffectsSdkLocal(localKey);
+        }
+        return EffectsSDKStatus.INACTIVE;
+    }
+
+    public void setEffectsSdkPipelineMode(String trackId, String pipelineMode) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setPipelineMode(pipelineMode);
+        }
+    }
+
+    public void enableEffectsSdkBeautification(String trackId, boolean enableBeautification) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.enableBeautification(enableBeautification);
+        }
+    }
+
+    public boolean isEffectsSdkBeautificationEnabled(String trackId) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            return capturer.isBeautificationEnabled();
+        }
+        return false;
+    }
+
+    public void setEffectsSdkBeautificationPower(String trackId, double beautificationPower) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setBeautificationPower(beautificationPower);
+        }
+    }
+
+    public double getEffectsSdkZoomLevel(String trackId) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            return capturer.getZoomLevel();
+        }
+        return 0;
+    }
+
+    public void setEffectsSdkZoomLevel(String trackId, double zoomLevel) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setZoomLevel(zoomLevel);
+        }
+    }
+
+    public void enableEffectsSdkSharpening(String trackId, boolean enableSharpening) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.enableSharpening(enableSharpening);
+        }
+    }
+
+    public double getEffectsSdkSharpeningStrength(String trackId) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            return capturer.getSharpeningStrength();
+        }
+        return 0;
+    }
+
+    public void setEffectsSdkSharpeningStrength(String trackId, double strength) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setSharpeningStrength(strength);
+        }
+    }
+
+    public void setEffectsSdkColorFilterStrength(String trackId, double strength) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setColorFilterStrength(strength);
+        }
+    }
+
+    public void setEffectsSdkBitmapImage(String trackId, Bitmap bitmap) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setBackgroundBitmap(bitmap);
+        }
+    }
+
+    public void setEffectsSdkColorGradingReferenceImage(String trackId, Bitmap bitmap) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setColorGradingReference(bitmap);
+        }
+    }
+
+    public void setEffectsSdkColorCorrectionMode(String trackId, String colorCorrectionMode) {
+        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
+        if (capturer != null) {
+            capturer.setColorCorrectionMode(colorCorrectionMode);
+        }
+    }
+
+    private EffectsSDKVideoCapturer getEffectsSdkVideoCapturer(String trackId) {
+        try {
+            VideoCapturerInfoEx info = mVideoCapturers.get(trackId);
+            if (info != null) {
+                return (EffectsSDKVideoCapturer) info.capturer;
+            }
+        } catch (ClassCastException e) {
+            Log.w(TAG, "Can't get EffectsSDKVideoCapturer instance. Make sure effectsSdkRequired is true.");
+        }
+        return null;
+    }
+
+
+
     public static class ScreenRequestPermissionsFragment extends Fragment {
 
         private ResultReceiver resultReceiver = null;
@@ -271,14 +412,24 @@ public class GetUserMediaImpl {
      * if not matched camera with specified facing mode.
      */
     private Pair<String, VideoCapturer> createVideoCapturer(
-            CameraEnumerator enumerator, boolean isFacing, String sourceId, CameraEventsHandler cameraEventsHandler) {
+            CameraEnumerator enumerator,
+            boolean isFacing,
+            String sourceId,
+            CameraEventsHandler cameraEventsHandler,
+            boolean effectsSdkRequired
+    ) {
         VideoCapturer videoCapturer;
         // if sourceId given, use specified sourceId first
         final String[] deviceNames = enumerator.getDeviceNames();
         if (sourceId != null && !sourceId.equals("")) {
             for (String name : deviceNames) {
                 if (name.equals(sourceId)) {
-                    videoCapturer = enumerator.createCapturer(name, cameraEventsHandler);
+                    if (!effectsSdkRequired) {
+                        videoCapturer = enumerator.createCapturer(name, cameraEventsHandler);
+                    } else {
+                        // Create EffectsSDK capturer here
+                        videoCapturer = new EffectsSDKVideoCapturer(name, cameraEventsHandler, enumerator);
+                    }
                     if (videoCapturer != null) {
                         Log.d(TAG, "create user specified camera " + name + " succeeded");
                         return new Pair<>(name, videoCapturer);
@@ -294,10 +445,14 @@ public class GetUserMediaImpl {
         String facingStr = isFacing ? "front" : "back";
         for (String name : deviceNames) {
             if (enumerator.isFrontFacing(name) == isFacing) {
-                videoCapturer = enumerator.createCapturer(name, cameraEventsHandler);
+                if (!effectsSdkRequired) {
+                    videoCapturer = enumerator.createCapturer(name, cameraEventsHandler);
+                } else {
+                    // Create EffectsSDK capturer here
+                    videoCapturer = new EffectsSDKVideoCapturer(name, cameraEventsHandler, enumerator);
+                }
                 if (videoCapturer != null) {
                     Log.d(TAG, "Create " + facingStr + " camera " + name + " succeeded");
-
                     return new Pair<>(name, videoCapturer);
                 } else {
                     Log.e(TAG, "Create " + facingStr + " camera " + name + " failed");
@@ -307,7 +462,12 @@ public class GetUserMediaImpl {
 
         // falling back to the first available camera
         if (deviceNames.length > 0) {
-            videoCapturer = enumerator.createCapturer(deviceNames[0], cameraEventsHandler);
+            if (!effectsSdkRequired) {
+                videoCapturer = enumerator.createCapturer(deviceNames[0], cameraEventsHandler);
+            } else {
+                // Create EffectsSDK capturer here
+                videoCapturer = new EffectsSDKVideoCapturer(deviceNames[0], cameraEventsHandler, enumerator);
+            }
             Log.d(TAG, "Falling back to the first available camera");
             return new Pair<>(deviceNames[0], videoCapturer);
         }
@@ -355,6 +515,17 @@ public class GetUserMediaImpl {
         return null;
     }
 
+    private boolean getEffectsSDKConstraint(ConstraintsMap mediaConstraints) {
+        try {
+            if (mediaConstraints != null && mediaConstraints.hasKey("effectsSdkRequired")) {
+                return mediaConstraints.getBoolean("effectsSdkRequired");
+            }
+        } catch (NullPointerException e) {
+            return false;
+        }
+        return false;
+    }
+
     private ConstraintsMap getUserAudio(ConstraintsMap constraints, MediaStream stream) {
         AudioSwitchManager.instance.start();
         MediaConstraints audioConstraints = new MediaConstraints();
@@ -723,8 +894,15 @@ public class GetUserMediaImpl {
         String facingMode = getFacingMode(videoConstraintsMap);
         isFacing = facingMode == null || !facingMode.equals("environment");
         String deviceId = getSourceIdConstraint(videoConstraintsMap);
+        boolean effectsSdkRequired = getEffectsSDKConstraint(videoConstraintsMap);
         CameraEventsHandler cameraEventsHandler = new CameraEventsHandler();
-        Pair<String, VideoCapturer> result = createVideoCapturer(cameraEnumerator, isFacing, deviceId, cameraEventsHandler);
+        Pair<String, VideoCapturer> result = createVideoCapturer(
+                cameraEnumerator,
+                isFacing,
+                deviceId,
+                cameraEventsHandler,
+                effectsSdkRequired
+        );
 
         if (result == null) {
             return null;
diff --git a/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java b/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java
index 8444c0e..ef79de1 100644
--- a/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java
+++ b/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java
@@ -5,16 +5,18 @@ import static com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils.parseMediaConst
 import android.app.Activity;
 import android.content.Context;
 import android.content.pm.PackageManager;
-import android.graphics.SurfaceTexture;
+import android.graphics.Bitmap;
+import android.graphics.BitmapFactory;
+import android.graphics.Canvas;
 import android.hardware.Camera;
 import android.hardware.Camera.CameraInfo;
 import android.media.MediaRecorder;
 import android.media.AudioAttributes;
 import android.media.AudioDeviceInfo;
 import android.os.Build;
+import android.os.Environment;
 import android.util.Log;
 import android.util.LongSparseArray;
-import android.view.Surface;
 
 import androidx.annotation.NonNull;
 import androidx.annotation.Nullable;
@@ -37,10 +39,10 @@ import com.cloudwebrtc.webrtc.utils.EglUtils;
 import com.cloudwebrtc.webrtc.utils.ObjectType;
 import com.cloudwebrtc.webrtc.utils.PermissionUtils;
 import com.cloudwebrtc.webrtc.utils.Utils;
-import com.cloudwebrtc.webrtc.video.VideoCapturerInfo;
 import com.cloudwebrtc.webrtc.video.camera.CameraUtils;
 import com.cloudwebrtc.webrtc.video.camera.Point;
 import com.cloudwebrtc.webrtc.video.LocalVideoTrack;
+import com.effectssdk.tsvb.EffectsSDKStatus;
 import com.twilio.audioswitch.AudioDevice;
 
 import org.webrtc.AudioTrack;
@@ -95,7 +97,6 @@ import io.flutter.plugin.common.MethodCall;
 import io.flutter.plugin.common.MethodChannel.MethodCallHandler;
 import io.flutter.plugin.common.MethodChannel.Result;
 import io.flutter.view.TextureRegistry;
-import io.flutter.view.TextureRegistry.SurfaceTextureEntry;
 
 public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
   static public final String TAG = "FlutterWebRTCPlugin";
@@ -1015,6 +1016,226 @@ public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
         }
         break;
       }
+      case "getPipelineMode": {
+        String trackId = call.argument("trackId");
+        break;
+      }
+      case "auth": {
+        String trackId = call.argument("trackId");
+        String customerKey = call.argument("customerKey");
+        String apiUrl = call.argument("apiUrl");
+        EffectsSDKStatus status = initializeEffectsSdk(trackId, customerKey, apiUrl);
+        result.success(status.toString());
+        break;
+      }
+      case "localAuth": {
+        String trackId = call.argument("trackId");
+        String localKey = call.argument("localKey");
+        result.success(initializeEffectsSdkLocal(trackId, localKey).toString());
+        break;
+      }
+      case "setPipelineMode": {
+        String trackId = call.argument("trackId");
+        String pipelineMode = call.argument("pipelineMode");
+        setEffectsSdkPipelineMode(trackId, pipelineMode);
+        break;
+      }
+      case "setBlurPower": {
+        String trackId = call.argument("trackId");
+        double blurPower = call.argument("blurPower");
+        setEffectsSdkBlurPower(trackId, blurPower);
+        result.success(null);
+        break;
+      }
+      case "setBackgroundImage": {
+        String trackId = call.argument("trackId");
+        HashMap<String, Object> userMap = call.argument("image");
+        if (userMap == null) {
+          Log.e(TAG, "Missing image data");
+          break;
+        }
+        String type = (String) userMap.get("type");
+        if (type == null) {
+          Log.e(TAG, "Image type required");
+          break;
+        }
+        switch (type) {
+          case "filepath": {
+            String path = (String) userMap.get("path");
+            File sd = Environment.getExternalStorageDirectory();
+            File image = new File(sd + path);
+            BitmapFactory.Options bmOptions = new BitmapFactory.Options();
+            Bitmap bitmap = BitmapFactory.decodeFile(image.getAbsolutePath(), bmOptions);
+            setEffectsSdkBackgroundImage(trackId, bitmap);
+            break;
+          }
+          case "encoded": {
+            byte[] bitmapBytes = call.argument("data");
+            Bitmap bitmap = BitmapFactory.decodeByteArray(bitmapBytes, 0, bitmapBytes.length);
+            if (bitmap != null) {
+              setEffectsSdkBackgroundImage(trackId, bitmap);
+            } else {
+              Log.e(TAG, "Decode bitmap error");
+            }
+            break;
+          }
+          case "rgb": {
+            double rComponent = (double) userMap.get("r");
+            double gComponent = (double) userMap.get("g");
+            double bComponent = (double) userMap.get("b");
+            byte r = (byte) (rComponent * 255);
+            byte g = (byte) (gComponent * 255);
+            byte b = (byte) (bComponent * 255);
+            int i = ((255) << 24) | ((0xFF & r) << 16) | ((0xFF & g) << 8) | (0xFF & b);
+            Bitmap bmp = Bitmap.createBitmap(50, 50, Bitmap.Config.ARGB_8888);
+            Canvas canvas = new Canvas(bmp);
+            canvas.drawColor(i);
+            setEffectsSdkBackgroundImage(trackId, bmp);
+            break;
+          }
+          case "raw": {
+            byte[] data = (byte[]) userMap.get("data");
+            //rgba only
+            String format = (String) userMap.get("format");
+            int width = (int) userMap.get("width");
+            int height = (int) userMap.get("height");
+            int stride = (int) userMap.get("stride");
+            Bitmap bmp = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888);
+            bmp.copyPixelsFromBuffer(ByteBuffer.wrap(data));
+            setEffectsSdkBackgroundImage(trackId, bmp);
+            break;
+          }
+          default:
+            Log.e(TAG, "Unknown image type");
+            break;
+        }
+        break;
+      }
+      case "enableBeautification": {
+        String trackId = call.argument("trackId");
+        boolean enableBeautification = call.argument("enable");
+        enableEffectsSdkBeautification(trackId, enableBeautification);
+        break;
+      }
+      case "isBeautificationEnabled": {
+        String trackId = call.argument("trackId");
+        boolean isEnabled = isEffectsSdkBeautificationEnabled(trackId);
+        result.success(isEnabled);
+        break;
+      }
+      case "setBeautificationPower": {
+        String trackId = call.argument("trackId");
+        double beautificationPower = call.argument("beautificationPower");
+        setEffectsSdkBeautificationPower(trackId, beautificationPower);
+        break;
+      }
+      case "getZoomLevel": {
+        String trackId = call.argument("trackId");
+        double zoomLevel = getEffectsSdkZoomLevel(trackId);
+        result.success(zoomLevel);
+        break;
+      }
+      case "setZoomLevel": {
+        String trackId = call.argument("trackId");
+        double zoomLevel = call.argument("zoomLevel");
+        setEffectsSdkZoomLevel(trackId, zoomLevel);
+        break;
+      }
+      case "enableSharpening": {
+        String trackId = call.argument("trackId");
+        boolean enableSharpening = call.argument("enable");
+        enableEffectsSdkSharpening(trackId, enableSharpening);
+        break;
+      }
+      case "getSharpeningStrength": {
+        String trackId = call.argument("trackId");
+        double sharpeningStrength = getEffectsSdkSharpeningStrength(trackId);
+        result.success(sharpeningStrength);
+        break;
+      }
+      case "setSharpeningStrength": {
+        String trackId = call.argument("trackId");
+        double strength = call.argument("strength");
+        setEffectsSdkSharpeningStrength(trackId, strength);
+        break;
+      }
+      case "setColorCorrectionMode": {
+        String trackId = call.argument("trackId");
+        String colorCorrectionMode = call.argument("colorCorrectionMode");
+        setEffectsSdkColorCorrectionMode(trackId, colorCorrectionMode);
+        break;
+      }
+      case "setColorFilterStrength": {
+        String trackId = call.argument("trackId");
+        double strength = call.argument("strength");
+        setEffectsSdkColorFilterStrength(trackId, strength);
+        break;
+      }
+      case "setColorGradingReferenceImage": {
+        String trackId = call.argument("trackId");
+        HashMap<String, Object> userMap = call.argument("image");
+        if (userMap == null) {
+          Log.e(TAG, "Missing image data");
+          break;
+        }
+        String type = (String) userMap.get("type");
+        if (type == null) {
+          Log.e(TAG, "Image type required");
+          break;
+        }
+        switch (type) {
+          case "filepath": {
+            String path = (String) userMap.get("path");
+            File sd = Environment.getExternalStorageDirectory();
+            File image = new File(sd + path);
+            BitmapFactory.Options bmOptions = new BitmapFactory.Options();
+            Bitmap bitmap = BitmapFactory.decodeFile(image.getAbsolutePath(), bmOptions);
+            setEffectsSdkColorGradingReferenceImage(trackId, bitmap);
+            break;
+          }
+          case "encoded": {
+            byte[] bitmapBytes = call.argument("data");
+            Bitmap bitmap = BitmapFactory.decodeByteArray(bitmapBytes, 0, bitmapBytes.length);
+            if (bitmap != null) {
+              setEffectsSdkColorGradingReferenceImage(trackId, bitmap);
+            } else {
+              Log.e(TAG, "Decode bitmap error");
+            }
+            break;
+          }
+          case "rgb": {
+            double rComponent = (double) userMap.get("r");
+            double gComponent = (double) userMap.get("g");
+            double bComponent = (double) userMap.get("b");
+            byte r = (byte) (rComponent * 255);
+            byte g = (byte) (gComponent * 255);
+            byte b = (byte) (bComponent * 255);
+            int i = ((255) << 24) | ((0xFF & r) << 16) | ((0xFF & g) << 8) | (0xFF & b);
+            Bitmap bmp = Bitmap.createBitmap(50, 50, Bitmap.Config.ARGB_8888);
+            Canvas canvas = new Canvas(bmp);
+            canvas.drawColor(i);
+            setEffectsSdkColorGradingReferenceImage(trackId, bmp);
+            break;
+          }
+          case "raw": {
+            byte[] data = (byte[]) userMap.get("data");
+            //rgba only
+            String format = (String) userMap.get("format");
+            int width = (int) userMap.get("width");
+            int height = (int) userMap.get("height");
+            int stride = (int) userMap.get("stride");
+            Bitmap bmp = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888);
+            bmp.copyPixelsFromBuffer(ByteBuffer.wrap(data));
+            setEffectsSdkColorGradingReferenceImage(trackId, bmp);
+            break;
+          }
+          default:
+            Log.e(TAG, "Unknown image type");
+            break;
+        }
+        break;
+      }
+
       default:
         if(frameCryptor.handleMethodCall(call, result)) {
           break;
@@ -1608,6 +1829,7 @@ public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
 
   public void mediaStreamTrackSetEnabled(final String id, final boolean enabled, String peerConnectionId) {
     MediaStreamTrack track = getTrackForId(id, peerConnectionId);
+    getUserMediaImpl.enableEffectsSdkVideoStream(id, enabled);
 
     if (track == null) {
       Log.d(TAG, "mediaStreamTrackSetEnabled() track is null");
@@ -2290,4 +2512,70 @@ public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
             activity,
             permissions.toArray(new String[permissions.size()]), callback);
   }
+
+
+  void setEffectsSdkBlurPower(String trackId, double blurPower) {
+    getUserMediaImpl.setEffectsSdkBlurPower(trackId, blurPower);
+  }
+
+  EffectsSDKStatus initializeEffectsSdk(String trackId, String customerKey, String apiUrl) {
+    return getUserMediaImpl.initializeEffectsSdk(trackId, customerKey, apiUrl);
+  }
+
+  EffectsSDKStatus initializeEffectsSdkLocal(String trackId, String localKey) {
+    return getUserMediaImpl.initializeEffectsSdkLocal(trackId, localKey);
+  }
+
+  private void setEffectsSdkPipelineMode(String trackId, String pipelineMode) {
+    getUserMediaImpl.setEffectsSdkPipelineMode(trackId, pipelineMode);
+  }
+
+  private void setEffectsSdkBackgroundImage(String trackId, Bitmap bitmap) {
+    getUserMediaImpl.setEffectsSdkBitmapImage(trackId, bitmap);
+  }
+
+  private void enableEffectsSdkBeautification(String trackId, boolean enableBeautification) {
+    getUserMediaImpl.enableEffectsSdkBeautification(trackId, enableBeautification);
+  }
+
+  private boolean isEffectsSdkBeautificationEnabled(String trackId) {
+    return getUserMediaImpl.isEffectsSdkBeautificationEnabled(trackId);
+  }
+
+  private void setEffectsSdkBeautificationPower(String trackId, double beautificationPower) {
+    getUserMediaImpl.setEffectsSdkBeautificationPower(trackId, beautificationPower);
+  }
+
+  private double getEffectsSdkZoomLevel(String trackId) {
+    return getUserMediaImpl.getEffectsSdkZoomLevel(trackId);
+  }
+
+  private void setEffectsSdkZoomLevel(String trackId, double zoomLevel) {
+    getUserMediaImpl.setEffectsSdkZoomLevel(trackId, zoomLevel);
+  }
+
+  private void enableEffectsSdkSharpening(String trackId, boolean enableSharpening) {
+    getUserMediaImpl.enableEffectsSdkSharpening(trackId, enableSharpening);
+  }
+
+  private double getEffectsSdkSharpeningStrength(String trackId) {
+    return getUserMediaImpl.getEffectsSdkSharpeningStrength(trackId);
+  }
+
+  private void setEffectsSdkSharpeningStrength(String trackId, double strength) {
+    getUserMediaImpl.setEffectsSdkSharpeningStrength(trackId, strength);
+  }
+
+  private void setEffectsSdkColorCorrectionMode(String trackId, String colorCorrectionMode) {
+    getUserMediaImpl.setEffectsSdkColorCorrectionMode(trackId, colorCorrectionMode);
+  }
+
+  private void setEffectsSdkColorFilterStrength(String trackId, double strength) {
+    getUserMediaImpl.setEffectsSdkColorFilterStrength(trackId, strength);
+  }
+
+  private void setEffectsSdkColorGradingReferenceImage(String trackId, Bitmap bitmap) {
+    getUserMediaImpl.setEffectsSdkColorGradingReferenceImage(trackId, bitmap);
+  }
+
 }
diff --git a/android/src/main/java/com/cloudwebrtc/webrtc/video/camera/EffectsSDKCameraCapturer.kt b/android/src/main/java/com/cloudwebrtc/webrtc/video/camera/EffectsSDKCameraCapturer.kt
new file mode 100644
index 0000000..1d414eb
--- /dev/null
+++ b/android/src/main/java/com/cloudwebrtc/webrtc/video/camera/EffectsSDKCameraCapturer.kt
@@ -0,0 +1,396 @@
+package com.cloudwebrtc.webrtc.video.camera
+
+import android.content.Context
+import android.graphics.Bitmap
+import android.util.Log
+import android.util.Size
+import com.effectssdk.tsvb.Camera
+import com.effectssdk.tsvb.EffectsSDK
+import com.effectssdk.tsvb.EffectsSDKStatus
+import com.effectssdk.tsvb.pipeline.CameraPipeline
+import com.effectssdk.tsvb.pipeline.ColorCorrectionMode
+import com.effectssdk.tsvb.pipeline.OnFrameAvailableListener
+import com.effectssdk.tsvb.pipeline.PipelineMode
+import kotlinx.coroutines.runBlocking
+import org.webrtc.CameraEnumerator
+import org.webrtc.CameraVideoCapturer
+import org.webrtc.CameraVideoCapturer.CameraEventsHandler
+import org.webrtc.CapturerObserver
+import org.webrtc.NV21Buffer
+import org.webrtc.SurfaceTextureHelper
+import org.webrtc.VideoFrame
+import java.net.URL
+import kotlin.coroutines.resume
+import kotlin.coroutines.suspendCoroutine
+
+
+/**
+ * Custom video capturer for Effects SDK
+ */
+class EffectsSDKVideoCapturer(
+    private val device: String,
+    private val eventsHandler: CameraEventsHandler,
+    enumerator: CameraEnumerator
+) : CameraVideoCapturer {
+
+    private var isPipelineCameraUsed: Boolean = false
+
+    private var context: Context? = null
+    private var capturerObserver: CapturerObserver? = null
+    //Default WebRTC capturer. Used until EffectsSDK not ready to provide frames
+    //You can remove this if you don't need non-processed frames
+    private var webRtcCameraCapturer: CameraVideoCapturer? = null
+
+    private var cameraPipeline: CameraPipeline? = null
+    private var defaultPipelineOptions = EffectsSdkOptionsCache()
+    private var currentPipelineOptions = EffectsSdkOptionsCache()
+
+    init {
+        //Custom event handler. Used until EffectsSDK not ready to provide frames
+        val cameraEventHandler = object : CameraEventsHandler {
+            override fun onCameraError(p0: String?) {
+                if (!isPipelineCameraUsed) eventsHandler.onCameraError(p0)
+            }
+
+            override fun onCameraDisconnected() {
+                if (!isPipelineCameraUsed) eventsHandler.onCameraDisconnected()
+            }
+
+            override fun onCameraFreezed(p0: String?) {
+                if (!isPipelineCameraUsed) eventsHandler.onCameraFreezed(p0)
+            }
+
+            override fun onCameraOpening(p0: String?) {
+                if (!isPipelineCameraUsed) eventsHandler.onCameraOpening(p0)
+            }
+
+            override fun onFirstFrameAvailable() {
+                if (!isPipelineCameraUsed) eventsHandler.onFirstFrameAvailable()
+            }
+
+            override fun onCameraClosed() {
+                if (!isPipelineCameraUsed) eventsHandler.onCameraClosed()
+            }
+
+        }
+        webRtcCameraCapturer = enumerator.createCapturer(device, cameraEventHandler)
+    }
+
+    override fun initialize(
+        surfaceTextureHelper: SurfaceTextureHelper?,
+        context: Context?,
+        observer: CapturerObserver?
+    ) {
+        if (!isPipelineCameraUsed) {
+            //Custom Capturer observer. Used until EffectsSDK not ready to provide frames
+            val nativeCapturerObserver = object : CapturerObserver {
+                override fun onCapturerStarted(p0: Boolean) {
+                    if (!isPipelineCameraUsed) capturerObserver?.onCapturerStarted(p0)
+                }
+
+                override fun onCapturerStopped() {
+                    if (!isPipelineCameraUsed) capturerObserver?.onCapturerStopped()
+
+                }
+
+                override fun onFrameCaptured(p0: VideoFrame?) {
+                    if (!isPipelineCameraUsed) capturerObserver?.onFrameCaptured(p0)
+                }
+            }
+            webRtcCameraCapturer?.initialize(surfaceTextureHelper, context, nativeCapturerObserver)
+        }
+        this.context = context
+        capturerObserver = observer
+    }
+
+
+    override fun startCapture(width: Int, height: Int, framerate: Int) {
+        if (!isPipelineCameraUsed) {
+            webRtcCameraCapturer?.startCapture(width, height, framerate)
+        } else {
+            createPipeline(height, width)
+            cameraPipeline?.startPipeline()
+            cameraPipeline?.setOnFrameAvailableListener(onFrameAvailableListener)
+        }
+    }
+
+    override fun stopCapture() {
+        if (!isPipelineCameraUsed) {
+            webRtcCameraCapturer?.stopCapture()
+        } else {
+            cameraPipeline?.setOnFrameAvailableListener(null)
+            cameraPipeline?.release()
+            cameraPipeline = null
+        }
+        eventsHandler.onCameraClosed()
+    }
+
+    private fun createPipeline(width: Int = 1280, height: Int = 720) {
+        val factory = EffectsSDK.createSDKFactory()
+        cameraPipeline = factory.createCameraPipeline(
+            context!!,
+            camera = if (device == "1") Camera.FRONT else Camera.BACK,
+            resolution = Size(width, height)
+        )
+        setPipelineOptionsFromCache(currentPipelineOptions)
+    }
+
+    /*
+     * If you don't need frames, you should set "empty" options to avoid background segmentation
+     */
+    fun enableVideo(enabled: Boolean) {
+        if (enabled) {
+            setPipelineOptionsFromCache(currentPipelineOptions)
+            cameraPipeline?.setOnFrameAvailableListener(onFrameAvailableListener)
+        } else {
+            setPipelineOptionsFromCache(defaultPipelineOptions)
+            cameraPipeline?.setOnFrameAvailableListener(null)
+        }
+    }
+
+    override fun changeCaptureFormat(width: Int, height: Int, framerate: Int) {
+        if (!isPipelineCameraUsed) {
+            webRtcCameraCapturer?.changeCaptureFormat(width, height, framerate)
+        }
+    }
+
+    override fun dispose() {
+        if (!isPipelineCameraUsed) {
+            webRtcCameraCapturer?.dispose()
+        }
+    }
+
+    override fun isScreencast(): Boolean {
+        return false
+    }
+
+    override fun switchCamera(switchEventsHandler: CameraVideoCapturer.CameraSwitchHandler?) {
+        if (!isPipelineCameraUsed) {
+            webRtcCameraCapturer?.switchCamera(switchEventsHandler)
+        }
+        switchEventsHandler?.onCameraSwitchDone(true)
+    }
+
+    override fun switchCamera(
+        switchEventsHandler: CameraVideoCapturer.CameraSwitchHandler?,
+        p1: String?
+    ) {
+        if (!isPipelineCameraUsed) {
+            webRtcCameraCapturer?.switchCamera(switchEventsHandler, p1)
+        }
+        switchEventsHandler?.onCameraSwitchDone(true)
+    }
+
+    private fun getNV21(scaled: Bitmap): ByteArray {
+        val argb = IntArray(scaled.width * scaled.height)
+        scaled.getPixels(argb, 0, scaled.width, 0, 0, scaled.width, scaled.height)
+        val yuv = ByteArray(scaled.width * scaled.height * 3 / 2)
+        encodeYUV420SP(yuv, argb, scaled.width, scaled.height)
+        return yuv
+    }
+
+    private fun encodeYUV420SP(yuv420sp: ByteArray, argb: IntArray, width: Int, height: Int) {
+        val frameSize = width * height
+
+        var yIndex = 0
+        var uvIndex = frameSize
+
+        var R: Int
+        var G: Int
+        var B: Int
+        var Y: Int
+        var U: Int
+        var V: Int
+        var index = 0
+        for (j in 0 until height) {
+            for (i in 0 until width) {
+                R = (argb[index] and 0xff0000) shr 16
+                G = (argb[index] and 0xff00) shr 8
+                B = (argb[index] and 0xff) shr 0
+
+                Y = ((66 * R + 129 * G + 25 * B + 128) shr 8) + 16
+                U = ((-38 * R - 74 * G + 112 * B + 128) shr 8) + 128
+                V = ((112 * R - 94 * G - 18 * B + 128) shr 8) + 128
+
+                yuv420sp[yIndex++] = Y.toByte()
+                if (j % 2 == 0 && index % 2 == 0) {
+                    yuv420sp[uvIndex++] = V.toByte()
+                    yuv420sp[uvIndex++] = U.toByte()
+                }
+
+                index++
+            }
+        }
+    }
+
+    private val onFrameAvailableListener = OnFrameAvailableListener { bitmap, timestamp ->
+        if (!isPipelineCameraUsed) {
+            isPipelineCameraUsed = true
+            webRtcCameraCapturer?.stopCapture()
+            webRtcCameraCapturer?.dispose()
+            webRtcCameraCapturer = null
+        }
+        val videoFrame = VideoFrame(
+            NV21Buffer(
+                getNV21(bitmap),
+                bitmap.width,
+                bitmap.height,
+                { bitmap.recycle() }
+            ),
+            0,
+            timestamp * 1_000_000 //millisectonds to nanoseconds
+        )
+        capturerObserver?.onFrameCaptured(videoFrame)
+    }
+
+    fun initializeEffectsSdk(customerId: String, url: String?): EffectsSDKStatus {
+        var result: EffectsSDKStatus
+        runBlocking {
+            result = if (url == null) {
+                initializeCallback(context!!, customerId)
+            } else {
+                initializeCallback(context!!, customerId, URL(url))
+            }
+        }
+        if (result == EffectsSDKStatus.ACTIVE) {
+            createPipeline()
+            cameraPipeline?.startPipeline()
+            cameraPipeline?.setOnFrameAvailableListener(onFrameAvailableListener)
+        }
+        return result
+    }
+
+    private suspend fun initializeCallback(
+        context: Context,
+        customerId: String,
+        url: URL? = null
+    ): EffectsSDKStatus {
+        return suspendCoroutine { continuation ->
+            EffectsSDK.initialize(context, customerId, url) { sdkStatus ->
+                continuation.resume(sdkStatus)
+            }
+        }
+    }
+
+    fun initializeEffectsSdkLocal(localKey: String): EffectsSDKStatus {
+        return EffectsSDK.initialize(context!!, localKey)
+    }
+
+    fun setPipelineMode(pipelineMode: String) {
+        var value: String = pipelineMode.split('.')[1]
+        if (value == "noEffects") value = "no_effect"
+        val mode: PipelineMode = PipelineMode.valueOf(value.uppercase())
+        currentPipelineOptions.pipelineMode = mode
+        cameraPipeline?.setMode(mode)
+    }
+
+    fun setBlurPower(blurPower: Float) {
+        currentPipelineOptions.blurPower = blurPower
+        cameraPipeline?.setBlurPower(blurPower)
+    }
+
+    fun enableBeautification(enableBeautification: Boolean) {
+        currentPipelineOptions.isBeautificationEnabled = enableBeautification
+        cameraPipeline?.enableBeautification(enableBeautification)
+    }
+
+    fun isBeautificationEnabled(): Boolean {
+        return cameraPipeline?.isBeautificationEnabled()!!
+    }
+
+    fun setBeautificationPower(power: Double) {
+        val intValue = (power * 100).toInt()
+        currentPipelineOptions.beautificationPower = intValue
+        cameraPipeline?.setBeautificationPower(intValue)
+    }
+
+    fun getZoomLevel(): Double {
+        return (cameraPipeline?.getZoomLevel()!! / 100).toDouble()
+    }
+
+    fun setZoomLevel(zoomLevel: Double) {
+        val intValue = (zoomLevel * 100).toInt()
+        currentPipelineOptions.zoomLevel = intValue
+        cameraPipeline?.setZoomLevel(intValue)
+    }
+
+    fun enableSharpening(enableSharpening: Boolean) {
+        currentPipelineOptions.isSharpeningEnabled = enableSharpening
+        cameraPipeline?.enableSharpening(enableSharpening)
+    }
+
+    fun getSharpeningStrength(): Double {
+        return cameraPipeline?.getSharpeningStrength()!!.toDouble()
+    }
+
+    fun setSharpeningStrength(strength: Double) {
+        currentPipelineOptions.sharpeningStrength = strength.toFloat()
+        cameraPipeline?.setSharpeningStrength(strength.toFloat())
+    }
+
+    fun setColorCorrectionMode(mode: String) {
+        val value: String = mode.split('.')[1]
+        val colorCorrectionMode = when (value) {
+            "noFilterMode" -> ColorCorrectionMode.NO_FILTER_MODE
+            "colorCorrectionMode" -> ColorCorrectionMode.COLOR_CORRECTION_MODE
+            "colorGradingMode" -> ColorCorrectionMode.COLOR_GRADING_MODE
+            "presetMode" -> ColorCorrectionMode.PRESET_MODE
+            "lowLightMode" -> ColorCorrectionMode.LOW_LIGHT_MODE
+            else -> {
+                Log.w(
+                    this.javaClass.simpleName,
+                    "Incorrect color correction constant value. NO_FILTER_MODE set."
+                )
+                ColorCorrectionMode.NO_FILTER_MODE
+            }
+        }
+        currentPipelineOptions.colorCorrectionMode = colorCorrectionMode
+        cameraPipeline?.setColorCorrectionMode(colorCorrectionMode)
+    }
+
+    fun setColorFilterStrength(strength: Double) {
+        currentPipelineOptions.colorFilterStrength = strength.toFloat()
+        cameraPipeline?.setColorFilterStrength(strength.toFloat())
+    }
+
+    fun setColorGradingReference(bitmap: Bitmap) {
+        currentPipelineOptions.colorGradingReference = bitmap
+        cameraPipeline?.setColorGradingReferenceImage(bitmap)
+    }
+
+    fun setBackgroundBitmap(bitmap: Bitmap) {
+        currentPipelineOptions.backgroundBitmap = bitmap
+        cameraPipeline?.setBackground(bitmap)
+    }
+
+    private fun setPipelineOptionsFromCache(cache: EffectsSdkOptionsCache) {
+        cameraPipeline?.let { pipeline ->
+            pipeline.setMode(cache.pipelineMode)
+            pipeline.setBlurPower(cache.blurPower)
+            pipeline.setColorCorrectionMode(cache.colorCorrectionMode)
+            pipeline.enableSharpening(cache.isSharpeningEnabled)
+            pipeline.enableBeautification(cache.isBeautificationEnabled)
+            pipeline.setBeautificationPower(cache.beautificationPower)
+            pipeline.setColorFilterStrength(cache.colorFilterStrength)
+            pipeline.setSharpeningStrength(cache.sharpeningStrength)
+            pipeline.setZoomLevel(cache.zoomLevel)
+            cache.backgroundBitmap?.let { img -> pipeline.setBackground(img) }
+            cache.colorGradingReference?.let { img -> pipeline.setColorGradingReferenceImage(img) }
+        }
+    }
+
+    private data class EffectsSdkOptionsCache(
+        var pipelineMode: PipelineMode = PipelineMode.NO_EFFECT,
+        var blurPower: Float = 0f,
+        var colorCorrectionMode: ColorCorrectionMode = ColorCorrectionMode.NO_FILTER_MODE,
+        var isSharpeningEnabled: Boolean = false,
+        var isBeautificationEnabled: Boolean = false,
+        var beautificationPower: Int = 0,
+        var colorFilterStrength: Float = 0f,
+        var sharpeningStrength: Float = 0f,
+        var zoomLevel: Int = 0,
+        var backgroundBitmap: Bitmap? = null,
+        var colorGradingReference: Bitmap? = null
+    )
+
+}
\ No newline at end of file
diff --git a/common/darwin/Classes/FlutterRTCMediaStream.m b/common/darwin/Classes/FlutterRTCMediaStream.m
index 5fb81ed..84c877d 100644
--- a/common/darwin/Classes/FlutterRTCMediaStream.m
+++ b/common/darwin/Classes/FlutterRTCMediaStream.m
@@ -4,6 +4,7 @@
 #import "FlutterRTCFrameCapturer.h"
 #import "FlutterRTCMediaStream.h"
 #import "FlutterRTCPeerConnection.h"
+#import "VideoEffectsSDKExts.h"
 #import "VideoProcessingAdapter.h"
 #import "LocalVideoTrack.h"
 #import "LocalAudioTrack.h"
@@ -488,6 +489,7 @@ - (void)getUserVideo:(NSDictionary*)constraints
       
     VideoProcessingAdapter *videoProcessingAdapter = [[VideoProcessingAdapter alloc] initWithRTCVideoSource:videoSource];
     self.videoCapturer = [[RTCCameraVideoCapturer alloc] initWithDelegate:videoProcessingAdapter];
+    [videoProcessingAdapter setSourceIsCamera:YES];
       
     AVCaptureDeviceFormat* selectedFormat = [self selectFormatForDevice:videoDevice
                                                             targetWidth:targetWidth
diff --git a/common/darwin/Classes/FlutterWebRTCPlugin.h b/common/darwin/Classes/FlutterWebRTCPlugin.h
index ee39d63..b8be5f4 100644
--- a/common/darwin/Classes/FlutterWebRTCPlugin.h
+++ b/common/darwin/Classes/FlutterWebRTCPlugin.h
@@ -13,6 +13,9 @@
 @class FlutterRTCMediaRecorder;
 @class AudioManager;
 
+@class VideoEffectsSDKContext;
+
+
 void postEvent(FlutterEventSink _Nonnull sink, id _Nullable event);
 
 typedef void (^CompletionHandler)(void);
@@ -46,6 +49,8 @@ typedef void (^CapturerStopHandler)(CompletionHandler _Nonnull handler);
 @property(nonatomic, strong)
     NSMutableDictionary<NSString*, RTCFrameCryptorKeyProvider*>* _Nullable keyProviders;
 
+@property(nonatomic, strong) VideoEffectsSDKContext* _Nullable vSdkContext;
+
 #if TARGET_OS_IPHONE
 @property(nonatomic, retain)
     UIViewController* _Nullable viewController; /*for broadcast or ReplayKit */
diff --git a/common/darwin/Classes/FlutterWebRTCPlugin.m b/common/darwin/Classes/FlutterWebRTCPlugin.m
index 73f01ae..94e57ee 100644
--- a/common/darwin/Classes/FlutterWebRTCPlugin.m
+++ b/common/darwin/Classes/FlutterWebRTCPlugin.m
@@ -18,6 +18,9 @@
 #import <WebRTC/RTCFieldTrials.h>
 #import <WebRTC/WebRTC.h>
 
+#import "VideoEffectsSDKContext.h"
+#import "VideoEffectsSDKExts.h"
+
 #import "LocalTrack.h"
 #import "LocalAudioTrack.h"
 #import "LocalVideoTrack.h"
@@ -104,6 +107,7 @@ @implementation FlutterWebRTCPlugin {
   BOOL _speakerOnButPreferBluetooth;
   AVAudioSessionPort _preferredInput;
   AudioManager* _audioManager;
+  VideoEffectsSDKContext* _vSdkContext;
 #if TARGET_OS_IPHONE
   FLutterRTCVideoPlatformViewFactory *_platformViewFactory;
 #endif
@@ -124,6 +128,8 @@ + (FlutterWebRTCPlugin *)sharedSingleton
 @synthesize preferredInput = _preferredInput;
 @synthesize audioManager = _audioManager;
 
+@synthesize vSdkContext = _vSdkContext;
+
 + (void)registerWithRegistrar:(NSObject<FlutterPluginRegistrar>*)registrar {
   FlutterMethodChannel* channel =
       [FlutterMethodChannel methodChannelWithName:@"FlutterWebRTC.Method"
@@ -1541,7 +1547,9 @@ - (void)handleMethodCall:(FlutterMethodCall*)call result:(FlutterResult)result {
                                                 details:nil]);
                 }
 #endif
-    } else {
+	} else if ([self handleEffectsSDKCall:call result:result]) {
+		
+	} else {
     [self handleFrameCryptorMethodCall:call result:result];
   }
 }
@@ -2379,4 +2387,375 @@ - (FlutterRTCVideoRenderer *)findRendererByTrackId:(NSString *)trackId {
     }
     return nil;
 }
+
+-(bool)handleEffectsSDKCall:(FlutterMethodCall*)call result:(FlutterResult)result {
+	if([@"auth" isEqualToString:call.method]) {
+		[self handleAuthCall:call result:result];
+		return true;
+	}
+	if([@"localAuth" isEqualToString:call.method]) {
+		[self handleLocalAuthCall:call result:result];
+		return true;
+	}
+	if ([@"setPipelineMode" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		NSString* pipelineMode = call.arguments[@"pipelineMode"];
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		if (![self checkAuth:call.method result:result]) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		FlutterError* error = [track.sdkPipelineController setPipelineMode:pipelineMode];
+		result(error);
+		return true;
+	}
+	if ([@"setBlurPower" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		float power = ((NSNumber*)call.arguments[@"blurPower"]).floatValue;
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		
+		[self ensureSDKControllerOfTrack:track];
+		[track.sdkPipelineController setBlurPower:power];
+		return true;
+	}
+	if ([@"setBackgroundImage" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		NSDictionary* imageParams = call.arguments[@"image"];
+		id<TSVBFrame> frame = [self loadImage:imageParams];
+		if (nil == frame) {
+			[self placeImageErrorToResult:result method:call.method];
+			return true;
+		}
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		[track.sdkPipelineController setBackground:frame];
+		result(nil);
+		return true;
+	}
+	if ([@"enableBeautification" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		bool enable = ((NSNumber*)call.arguments[@"enable"]).boolValue;
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		if (![self checkAuth:call.method result:result]) {
+			return true;
+		}
+		if (!enable && (nil == track.sdkPipelineController)) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		FlutterError* error = [track.sdkPipelineController setBeautificationEnabled:enable];
+		result(error);
+		return true;
+	}
+	if ([@"isBeautificationEnabled" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		result([NSNumber numberWithBool:[[track sdkPipelineController] beautificationEnabled]]);
+		return true;
+	}
+	if ([@"setBeautificationPower" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		float power = ((NSNumber*)call.arguments[@"beautificationPower"]).floatValue;
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		track.sdkPipelineController.beautificationPower = power;
+		result(nil);
+		return true;
+	}
+	if ([@"getZoomLevel" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		result([NSNumber numberWithFloat:[[track sdkPipelineController] zoomLevel]]);
+		return true;
+	}
+	if ([@"setZoomLevel" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		float level = ((NSNumber*)call.arguments[@"zoomLevel"]).floatValue;
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		if (![self checkAuth:call.method result:result]) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		FlutterError* error = 
+			[track.sdkPipelineController setZoomLevel:level];
+		result(error);
+		return true;
+	}
+	if ([@"enableSharpening" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		bool enabled = ((NSNumber*)call.arguments[@"enable"]).boolValue;
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		if (![self checkAuth:call.method result:result]) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		FlutterError* error = 
+			[track.sdkPipelineController setSharpeningEnabled:enabled];
+		result(error);
+		return true;
+	}
+	if ([@"getSharpeningStrength" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		result([NSNumber numberWithFloat:track.sdkPipelineController.sharpeningStrength]);
+		return true;
+	}
+	if ([@"setSharpeningStrength" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		float strength = ((NSNumber*)call.arguments[@"strength"]).floatValue;
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		track.sdkPipelineController.sharpeningStrength = strength;
+		result(nil);
+		return true;
+	}
+	if ([@"setColorCorrectionMode" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		NSString* mode = call.arguments[@"colorCorrectionMode"];
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		if (![self checkAuth:call.method result:result]) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		FlutterError* error = [track.sdkPipelineController setColorFilterMode:mode];
+		result(error);
+		return true;
+	}
+	if ([@"setColorFilterStrength" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		float strength = ((NSNumber*)call.arguments[@"strength"]).floatValue;
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		track.sdkPipelineController.sharpeningStrength = strength;
+		result(nil);
+		return true;
+	}
+	if ([@"setColorGradingReferenceImage" isEqualToString:call.method]) {
+		NSString* trackId = call.arguments[@"trackId"];
+		id<TSVBFrame> frame = [self loadImage:call.arguments[@"reference"]];
+		if (nil == frame) {
+			[self placeImageErrorToResult:result method:call.method];
+			return true;
+		}
+		LocalVideoTrack* track = 
+			[self getLocalVideoTrackForEffectsSDKWithId:trackId method:call.method result:result];
+		if (nil == track) {
+			return true;
+		}
+		[self ensureSDKControllerOfTrack:track];
+		track.sdkPipelineController.colorGradingReference = frame;
+		result(nil);
+		return true;
+	}
+	
+	return false;
+}
+
+-(LocalVideoTrack*)getLocalVideoTrackForEffectsSDKWithId:(NSString*)trackId method:(NSString*)method result:(FlutterResult)result {
+	id<LocalTrack> localTrack = [_localTracks objectForKey:trackId];
+	if ((nil != localTrack) && [localTrack isKindOfClass:[LocalVideoTrack class]]) {
+		return localTrack;
+	}
+	
+	result([FlutterError errorWithCode:[NSString stringWithFormat:@"%@ failed", method]
+							  message:@"Error: Video Effects SDK is only available for Local Video Tracks"
+								details:nil]);
+	return nil;
+}
+
+-(void)ensureSDKControllerOfTrack:(nonnull LocalVideoTrack*)track {
+	if (nil == track.sdkPipelineController) {
+		[self ensureVideoEffectsSDKContext];
+		track.sdkPipelineController = [_vSdkContext newPipelineControllerWithAdapter:track.processing];
+	}
+}
+
+-(bool)checkAuth:(NSString*)method result:(FlutterResult)result {
+	if (nil != _vSdkContext) {
+		enum AuthState state = _vSdkContext.authState;
+		if (AuthStateAuthorized == state) {
+			return true;
+		}
+	}
+	
+	result([FlutterError errorWithCode:[NSString stringWithFormat:@"%@ failed", method]
+							  message:@"Error: Video Effects SDK is not authorizaed"
+								details:nil]);
+	return false;
+}
+
+-(void)ensureVideoEffectsSDKContext {
+	if (nil != _vSdkContext) {
+		return;
+	}
+	
+	_vSdkContext = [VideoEffectsSDKContext new];
+}
+
+-(void)handleAuthCall:(FlutterMethodCall*)call result:(FlutterResult)result {
+	if (nil != _vSdkContext) {
+		enum AuthState state = _vSdkContext.authState;
+		if (AuthStateAuthorizing == state) {
+			result([FlutterError errorWithCode:[NSString stringWithFormat:@"%@ failed",call.method]
+									  message:@"Error: Authorization is already in progress"
+										details:nil]);
+			return;
+		}
+		if (AuthStateAuthorized == state) {
+			result(nameOfAuthStatus(TSVBAuthStatusActive));
+			return;
+		}
+	}
+	NSDictionary* argsMap = call.arguments;
+	NSString* customerID = argsMap[@"customerKey"];
+	id apiUrlObject = argsMap[@"apiUrl"];
+	NSString* apiUrl = nil;
+	if ((nil != apiUrlObject) && ([NSNull null] != apiUrlObject)) {
+		apiUrl = apiUrlObject;
+	}
+	if (nil == customerID || customerID.length < 1) {
+		result([FlutterError errorWithCode:[NSString stringWithFormat:@"%@ failed",call.method]
+								  message:@"Error: customerID must not be empty!"
+									details:nil]);
+		return;
+	}
+	
+	[self ensureVideoEffectsSDKContext];
+	
+	_vSdkContext.authState = AuthStateAuthorizing;
+	VideoEffectsSDKContext* context = _vSdkContext;
+	[_vSdkContext.sdkFactory authWithCustomerID:customerID
+										 apiUrl:[NSURL URLWithString:apiUrl]
+							  completionHandler:^(id<TSVBAuthResult>  _Nullable authResult, NSError * _Nullable error) {
+		if (nil != error) {
+			context.authState = AuthStateNotAuthorized;
+			result([FlutterError errorWithCode:@"Authorization error"
+									  message:error.localizedDescription
+										details:nil]);
+			return;
+		}
+		
+		context.authState = (TSVBAuthStatusActive == authResult.status)? 
+			AuthStateAuthorized : AuthStateNotAuthorized;
+		result(nameOfAuthStatus(authResult.status));
+	}];
+}
+
+-(void)handleLocalAuthCall:(FlutterMethodCall*)call result:(FlutterResult)result {
+	if (nil != _vSdkContext) {
+		enum AuthState state = _vSdkContext.authState;
+		if (AuthStateAuthorizing == state) {
+			result([FlutterError errorWithCode:[NSString stringWithFormat:@"%@ failed",call.method]
+									  message:@"Error: Authorization is already in progress"
+										details:nil]);
+			return;
+		}
+		if (AuthStateAuthorized == state) {
+			result(nameOfAuthStatus(TSVBAuthStatusActive));
+			return;
+		}
+	}
+	NSDictionary* argsMap = call.arguments;
+	NSString* localKey = argsMap[@"localKey"];
+	[self ensureVideoEffectsSDKContext];
+	id<TSVBAuthResult> authResult = [_vSdkContext.sdkFactory authWithKey:localKey];
+	_vSdkContext.authState = (TSVBAuthStatusActive == authResult.status)?
+		AuthStateAuthorized : AuthStateNotAuthorized;
+	
+	result(nameOfAuthStatus(authResult.status));
+}
+
+-(id<TSVBFrame>)loadImage:(NSDictionary*)params {
+	NSString* type = params[@"type"];
+	if ([@"encoded" isEqualToString:type]) {
+		FlutterStandardTypedData* typedData = params[@"data"];
+		NSData* data = typedData.data;
+		return [[_vSdkContext frameFactory] imageWithData:data];
+	}
+	if ([@"rgb" isEqualToString:type]) {
+		float r = ((NSNumber*)params[@"r"]).floatValue;
+		float g = ((NSNumber*)params[@"g"]).floatValue;
+		float b = ((NSNumber*)params[@"b"]).floatValue;
+		return [SDKFrameFactoryHelper solidFrameWithRed:r green:g blue:b factory:[_vSdkContext frameFactory]];
+	}
+	if ([@"filepath" isEqualToString:type]) {
+		NSString* path = params[@"path"];
+		return [[_vSdkContext frameFactory] imageWithContentOfFile:path];
+	}
+	if ([@"raw" isEqualToString:type]) {
+		NSData* data= ((FlutterStandardTypedData*)params[@"data"]).data;
+		int width = ((NSNumber*)params[@"width"]).intValue;
+		int height = ((NSNumber*)params[@"height"]).intValue;
+		int stride = ((NSNumber*)params[@"stride"]).intValue;
+		return [[_vSdkContext frameFactory] newFrameWithFormat:TSVBFrameFormatRgba32
+														  data:(void*)data.bytes
+												  bytesPerLine:stride
+														 width:width
+														height:height
+													  makeCopy:true];
+	}
+	return nil;
+}
+
+-(void)placeImageErrorToResult:(FlutterResult)result method:(NSString*)method {
+	result(
+		[FlutterError errorWithCode:[NSString stringWithFormat:@"%@ failed", method]
+							message:@"Failure to load image"
+							details:nil]
+	);
+}
+
 @end
diff --git a/common/darwin/Classes/VideoEffectsSDKContext.h b/common/darwin/Classes/VideoEffectsSDKContext.h
new file mode 100644
index 0000000..a244482
--- /dev/null
+++ b/common/darwin/Classes/VideoEffectsSDKContext.h
@@ -0,0 +1,69 @@
+#import <TSVB/TSVB.h>
+#import <Flutter/Flutter.h>
+#import "VideoProcessingAdapter.h"
+
+typedef NS_ENUM(NSUInteger, AuthState) {
+	AuthStateNotAuthorized,
+	AuthStateAuthorizing,
+	AuthStateAuthorized
+};
+
+typedef NS_ENUM(NSUInteger, ColorFilterError) {
+	noError,
+	unknownMode,
+	noGradingReference,
+	initializationFailed
+};
+
+NSString* _Nonnull nameOfAuthStatus(TSVBAuthStatus status);
+
+@interface VideoEffectsSDKPipelineWrapper : NSObject<ExternalVideoProcessingDelegate>
+
+- (nonnull instancetype)initWithSDKPipeline:(nonnull id<TSVBPipeline>)pipeline frameFactory:(nonnull id<TSVBFrameFactory>)frameFactory;
+
+@property(nonatomic, readonly, nonnull) id<TSVBPipeline> pipeline;
+@property(nonatomic, strong, nullable) id<TSVBReplacementController> replacementController;
+@property(nonatomic) bool sourceIsCamera;
+
+-(void)lock;
+-(void)unlock;
+
+@end
+
+@interface VideoEffectsSDKPipelineController: NSObject
+
+-(nonnull instancetype)initWithSDKFactory:(nonnull TSVBSDKFactory*)factory frameFactory:(nonnull id<TSVBFrameFactory>)frameFactory adapter:(nonnull VideoProcessingAdapter*)adapter;
+
+-(nullable FlutterError*)setPipelineMode:(nonnull NSString*)mode;
+-(nullable FlutterError*)setBeautificationEnabled:(bool)enabled;
+-(nullable FlutterError*)setZoomLevel:(float)level;
+-(nullable FlutterError*)setSharpeningEnabled:(bool)enabled;
+-(nullable FlutterError*)setColorFilterMode:(nonnull NSString*)mode;
+
+@property(nonatomic) float blurPower;
+@property(nonatomic, readonly) bool beautificationEnabled;
+@property(nonatomic) float beautificationPower;
+@property(nonatomic, readonly) float zoomLevel;
+@property(nonatomic) float sharpeningStrength;
+@property(nonatomic) float colorFilterStrength;
+@property(nonatomic, strong) _Nullable id<TSVBFrame> background;
+@property(nonatomic, strong) _Nullable id<TSVBFrame> colorGradingReference;
+
+@end
+
+@interface VideoEffectsSDKContext : NSObject
+
+@property(nonatomic, strong, readonly, nullable) TSVBSDKFactory* sdkFactory;
+@property(nonatomic, strong, readonly, nullable) id<TSVBFrameFactory> frameFactory;
+
+@property(atomic) enum AuthState authState;
+
+-(nonnull VideoEffectsSDKPipelineController*) newPipelineControllerWithAdapter:(nonnull VideoProcessingAdapter*)adapter;
+
+@end
+
+@interface SDKFrameFactoryHelper : NSObject
+
++(nullable id<TSVBFrame>)solidFrameWithRed:(float)r green:(float)g blue:(float)b factory:(nullable  id<TSVBFrameFactory>)factory;
+
+@end
diff --git a/common/darwin/Classes/VideoEffectsSDKContext.m b/common/darwin/Classes/VideoEffectsSDKContext.m
new file mode 100644
index 0000000..a3f4835
--- /dev/null
+++ b/common/darwin/Classes/VideoEffectsSDKContext.m
@@ -0,0 +1,636 @@
+#import "VideoEffectsSDKContext.h"
+#import "VideoEffectsSDKExts.h"
+#import <os/lock.h>
+
+typedef enum ColorFilterMode_ {
+	noColorFilter,
+	mlColorCorrection,
+	colorGrading,
+	lowLight,
+} ColorFilterMode;
+
+static TSVBRotation toTSVBRotation(RTCVideoRotation rtcRotation) 
+{
+	return (TSVBRotation)((360 - (int)rtcRotation) % 360);
+}
+
+static ColorFilterMode mapColorFilterName(NSString* mode) {
+	NSDictionary<NSString*, NSNumber*>* modeNameMap = @{
+		@"ColorCorrectionMode.noFilterMode" : @(noColorFilter),
+		@"ColorCorrectionMode.colorCorrectionMode" : @(mlColorCorrection),
+		@"ColorCorrectionMode.colorGradingMode" : @(colorGrading),
+		@"ColorCorrectionMode.lowLightMode" : @(lowLight),
+	};
+	
+	NSNumber* modeNum = modeNameMap[mode];
+	return [modeNum intValue];
+}
+
+@implementation VideoEffectsSDKPipelineWrapper
+{
+	os_unfair_lock _lock;
+	id<TSVBPipeline> _sdkPipeline;
+	id<TSVBReplacementController> _replacementController;
+	id<TSVBFrameFactory> _frameFactory;
+	bool _sourceIsCamera;
+	
+	NSMutableData* _bgraData;
+	id<TSVBFrame> _bgraInput;
+}
+
+@synthesize replacementController = _replacementController;
+@synthesize sourceIsCamera = _sourceIsCamera;
+
+-(instancetype)initWithSDKPipeline:(id<TSVBPipeline>)pipeline frameFactory:(id<TSVBFrameFactory> _Nonnull)frameFactory {
+	self = [super init];
+	if (self) {
+		_sdkPipeline = pipeline;
+		_frameFactory = frameFactory;
+		_lock = OS_UNFAIR_LOCK_INIT;
+	}
+	return self;
+}
+
+- (nonnull RTC_OBJC_TYPE(RTCVideoFrame)*)onFrame:(RTC_OBJC_TYPE(RTCVideoFrame)* _Nonnull)frame {
+	id<RTC_OBJC_TYPE(RTCVideoFrameBuffer)> frameBuffer = [frame buffer];
+	bool isPixelBuffer = [frameBuffer isKindOfClass:[RTC_OBJC_TYPE(RTCCVPixelBuffer) class]];
+	
+	id<TSVBFrame> result = nil;
+	if (isPixelBuffer) {
+		RTC_OBJC_TYPE(RTCCVPixelBuffer)* pb = frameBuffer;
+		[self lock];
+		result = [_sdkPipeline processCVPixelBuffer:pb.pixelBuffer
+									metalCompatible:_sourceIsCamera
+										   rotation:toTSVBRotation(frame.rotation)
+											  error:nil];
+		[self unlock];
+	}
+	else {
+		id<TSVBFrame> inputFrame = [self toTSVBFrame:frame];
+		[self lock];
+		result = [_sdkPipeline process:inputFrame error:nil];
+		[self unlock];
+	}
+	if (nil != result) {
+		return [self toRTCFrame:result rotation:frame.rotation timestamp:frame.timeStampNs];
+	}
+	return frame;
+}
+
+-(id<TSVBFrame>)toTSVBFrame:(RTC_OBJC_TYPE(RTCVideoFrame)* _Nonnull)rtcFrame {
+	id<RTC_OBJC_TYPE(RTCVideoFrameBuffer)> buffer = [rtcFrame buffer];
+	id<RTC_OBJC_TYPE(RTCI420Buffer)> i420Buffer = [buffer toI420];
+	id<TSVBFrame> bgraFrame = [self provideBGRAFrameWithWidth:rtcFrame.width height:rtcFrame.height];
+	if (nil == bgraFrame) {
+		return nil;
+	}
+	bgraFrame.rotation = toTSVBRotation(rtcFrame.rotation);
+	
+	id<TSVBLockedFrameData> lockedFrameData = [bgraFrame lock:TSVBFrameLockWrite];
+	[RTC_OBJC_TYPE(RTCYUVHelper) I420ToARGB:i420Buffer.dataY
+								 srcStrideY:i420Buffer.strideY
+									   srcU:i420Buffer.dataU
+								 srcStrideU:i420Buffer.strideU
+									   srcV:i420Buffer.dataV
+								 srcStrideV:i420Buffer.strideV
+									dstARGB:[lockedFrameData dataPointerOfPlanar:0]
+							  dstStrideARGB:[lockedFrameData bytesPerLineOfPlanar:0]
+									  width:rtcFrame.width
+									 height:rtcFrame.height];
+	lockedFrameData = nil;
+	return bgraFrame;
+}
+
+-(id<TSVBFrame>)provideBGRAFrameWithWidth:(int)w height:(int)h {
+	if (nil != _bgraInput) {
+		if ((_bgraInput.width != w) || (_bgraInput.height != h)) {
+			_bgraInput = nil;
+		}
+	}
+	if (nil != _bgraInput) {
+		return _bgraInput;
+	}
+	
+	size_t requiredSize = w * h * 4;
+	if ((nil == _bgraData) || (_bgraData.length < requiredSize)) {
+		_bgraData = [NSMutableData dataWithLength:requiredSize];
+		if (nil == _bgraData) {
+			return nil;
+		}
+	}
+	
+	_bgraInput = [_frameFactory newFrameWithFormat:TSVBFrameFormatBgra32
+											  data:[_bgraData mutableBytes]
+									  bytesPerLine:w * 4
+											 width:w
+											height:h
+										  makeCopy:false];
+	return _bgraInput;
+}
+
+-(RTC_OBJC_TYPE(RTCVideoFrame)*)toRTCFrame:(id<TSVBFrame>)frame rotation:(RTCVideoRotation)rotation timestamp:(int64_t)timestamp{
+	RTC_OBJC_TYPE(RTCCVPixelBuffer)* buffer =
+		[[RTC_OBJC_TYPE(RTCCVPixelBuffer) alloc] initWithPixelBuffer:[frame toCVPixelBuffer]];
+	return [[RTC_OBJC_TYPE(RTCVideoFrame) alloc] initWithBuffer:buffer rotation:rotation timeStampNs:timestamp];
+}
+
+- (void)lock {
+	os_unfair_lock_lock(&_lock);
+}
+
+- (void)unlock {
+	os_unfair_lock_unlock(&_lock);
+}
+
+-(id<TSVBPipeline>)pipeline {
+	return _sdkPipeline;
+}
+
+@end
+
+@implementation VideoEffectsSDKPipelineController
+{
+	TSVBSDKFactory* _sdkFactory;
+	id<TSVBFrameFactory> _frameFactory;
+	VideoProcessingAdapter* _adapter;
+	
+	VideoEffectsSDKPipelineWrapper* _wrapper;
+	id<TSVBFrame> _background;
+	id<TSVBFrame> _colorGradingReference;
+	bool _isInserted;
+	
+	float _blurPower;
+	float _beautificationPower;
+	float _zoomLevel;
+	float _sharpeningStrength;
+	float _colorFilterStrength;
+	
+	bool _blurEnabled;
+	bool _replaceEnabled;
+	bool _removeEnabled;
+	bool _beautificationEnabled;
+	bool _zoomEnabled;
+	bool _sharpeningEnabled;
+	ColorFilterMode _colorFilterMode;
+}
+
+- (nonnull instancetype)initWithSDKFactory:(nonnull TSVBSDKFactory *)factory frameFactory:(nonnull id<TSVBFrameFactory>)frameFactory adapter:(nonnull VideoProcessingAdapter*)adapter{
+	self = [super init];
+	if (self) {
+		_sdkFactory = factory;
+		_frameFactory = frameFactory;
+		_adapter = adapter;
+		_blurPower = 0.7;
+		_beautificationPower = 0.7;
+		_zoomLevel = 0.7;
+		_sharpeningStrength = 0.7;
+		_colorFilterStrength = 0.7;
+	}
+	return self;
+}
+
+- (nullable FlutterError*)setPipelineMode:(nonnull NSString*)mode {
+	if ([@"PipelineMode.noEffects" isEqualToString:mode] && (nil == _wrapper)) {
+		return nil;
+	}
+	VideoEffectsSDKPipelineWrapper* wrapper = [self provideWrapper];
+	
+	[wrapper lock];
+	TSVBPipelineError result = [self setPipelineModeImpl:mode wrapper:wrapper];
+	[wrapper unlock];
+	
+	[self ensureWrapper];
+	
+	return [self flutterErrorWithPipelineError:result method:@"setPipelineMode"];
+}
+
+- (TSVBPipelineError)setPipelineModeImpl:(nonnull NSString*)mode wrapper:(nonnull VideoEffectsSDKPipelineWrapper*)wrapper {
+	if ([@"PipelineMode.noEffects" isEqualToString:mode]) {
+		[wrapper.pipeline disableBlurBackground];
+		_blurEnabled = false;
+		[wrapper.pipeline disableReplaceBackground];
+		wrapper.replacementController = nil;
+		_removeEnabled = false;
+		_replaceEnabled = false;
+		return TSVBPipelineErrorOk;
+	}
+	
+	if ([@"PipelineMode.blur" isEqualToString:mode]) {
+		TSVBPipelineError result = [wrapper.pipeline enableBlurBackgroundWithPower:_blurPower];
+		_blurEnabled = (TSVBPipelineErrorOk == result);
+		if (_blurEnabled) {
+			[wrapper.pipeline disableReplaceBackground];
+			wrapper.replacementController = nil;
+			_removeEnabled = false;
+			_replaceEnabled = false;
+		}
+		return result;
+	}
+	
+	bool isReplacement =
+	[@"PipelineMode.replace" isEqualToString:mode] || [@"PipelineMode.remove" isEqualToString:mode];
+	if (isReplacement && (nil == wrapper.replacementController)) {
+		id<TSVBReplacementController> controller;
+		TSVBPipelineError result = [wrapper.pipeline enableReplaceBackground:&controller];
+		if (TSVBPipelineErrorOk == result) {
+			wrapper.replacementController = controller;
+			[wrapper.pipeline disableBlurBackground];
+			_blurEnabled = false;
+		}
+		else {
+			return result;
+		}
+	}
+	
+	if ([@"PipelineMode.replace" isEqualToString:mode]) {
+		_removeEnabled = false;
+		_replaceEnabled = true;
+		if (nil == _background) {
+			_background = [self defaultBackground];
+		}
+		wrapper.replacementController.background = _background;
+		return TSVBPipelineErrorOk;
+	}
+	if([@"PipelineMode.remove" isEqualToString:mode]) {
+		_removeEnabled = true;
+		_replaceEnabled = false;
+		wrapper.replacementController.background = nil;
+		return TSVBPipelineErrorOk;
+	}
+	
+	return TSVBPipelineErrorInvalidArgument;
+}
+
+-(float)blurPower {
+	return self->_blurPower;
+}
+
+-(void)setBlurPower:(float)blurPower {
+	self->_blurPower = blurPower;
+	if (_blurEnabled) {
+		[_wrapper lock];
+		[[_wrapper pipeline] enableBlurBackgroundWithPower:blurPower];
+		[_wrapper unlock];
+	}
+}
+
+-(id<TSVBFrame>)background {
+	return _background;
+}
+
+-(void)setBackground:(id<TSVBFrame>)background {
+	_background = background;
+	if (_replaceEnabled) {
+		[_wrapper lock];
+		[[_wrapper replacementController] setBackground:background];
+		[_wrapper unlock];
+	}
+}
+
+-(bool)beautificationEnabled {
+	return _beautificationEnabled;
+}
+
+-(nullable FlutterError*)setBeautificationEnabled:(bool)enabled
+{
+	if (enabled == _beautificationEnabled) {
+		return nil;
+	}
+	
+	VideoEffectsSDKPipelineWrapper* wrapper = [self provideWrapper];
+	
+	[wrapper lock];
+	TSVBPipelineError result = [self setBeautificationEnabledImpl:enabled wrapper:wrapper];
+	[wrapper unlock];
+	
+	[self ensureWrapper];
+	
+	return 	[self flutterErrorWithPipelineError:result method:@"enableBeautification"];
+}
+
+-(TSVBPipelineError)setBeautificationEnabledImpl:(bool)enabled wrapper:(nonnull VideoEffectsSDKPipelineWrapper*)wrapper
+{
+	if (!enabled) {
+		[wrapper.pipeline disableBeautification];
+		_beautificationEnabled = false;
+		return TSVBPipelineErrorOk;
+	}
+	
+	TSVBPipelineError result = [wrapper.pipeline enableBeautification];
+	_beautificationEnabled = (TSVBPipelineErrorOk == result);
+	if (_beautificationEnabled) {
+		wrapper.pipeline.beautificationLevel = _beautificationPower;
+	}
+	
+	return result;
+}
+
+-(float)beautificationPower {
+	return _beautificationPower;
+}
+
+-(void)setBeautificationPower:(float)beautificationPower {
+	_beautificationPower = beautificationPower;
+	if (_beautificationEnabled) {
+		[_wrapper lock];
+		_wrapper.pipeline.beautificationLevel = _beautificationPower;
+		[_wrapper unlock];
+	}
+}
+
+-(float)zoomLevel {
+	return _zoomLevel;
+}
+
+-(nullable FlutterError*)setZoomLevel:(float)value {
+	value = MIN(MAX(value, 0), 1);
+	if (value == _zoomLevel) {
+		return nil;
+	}
+	
+	VideoEffectsSDKPipelineWrapper* wrapper = [self provideWrapper];
+	
+	[wrapper lock];
+	TSVBPipelineError result = [self setZoomLevel:value wrapper:wrapper];
+	[wrapper unlock];
+	
+	[self ensureWrapper];
+	
+	return [self flutterErrorWithPipelineError:result method:@"setZoomLevel"];
+}
+
+-(TSVBPipelineError)setZoomLevel:(float)value wrapper:(nonnull VideoEffectsSDKPipelineWrapper*)wrapper
+{
+	if (value < 0.0001) {
+		[wrapper.pipeline disableSmartZoom];
+		_zoomEnabled = false;
+		_zoomLevel = value;
+		return TSVBPipelineErrorOk;
+	}
+	
+	TSVBPipelineError result = [wrapper.pipeline enableSmartZoom];
+	_zoomEnabled = (TSVBPipelineErrorOk == result);
+	if (_zoomEnabled) {
+		wrapper.pipeline.smartZoomLevel = value;
+		_zoomLevel = value;
+	}
+	
+	return result;
+}
+
+-(nullable FlutterError*)setSharpeningEnabled:(bool)enabled {
+	if (enabled == _sharpeningEnabled) {
+		return nil;
+	}
+	
+	VideoEffectsSDKPipelineWrapper* wrapper = [self provideWrapper];
+	
+	[wrapper lock];
+	TSVBPipelineError result = [self setSharpeningEnabled:enabled wrapper:wrapper];
+	[wrapper unlock];
+	
+	[self ensureWrapper];
+	
+	return [self flutterErrorWithPipelineError:result method:@"enableSharpening"];
+}
+
+-(TSVBPipelineError)setSharpeningEnabled:(bool)enabled wrapper:(nonnull VideoEffectsSDKPipelineWrapper*)wrapper
+{
+	if (!enabled) {
+		[wrapper.pipeline disableSharpening];
+		_sharpeningEnabled = false;
+		return TSVBPipelineErrorOk;
+	}
+	
+	TSVBPipelineError result = [wrapper.pipeline enableSharpening];
+	_sharpeningEnabled = (TSVBPipelineErrorOk == result);
+	if (_sharpeningEnabled) {
+		wrapper.pipeline.sharpeningPower = _sharpeningStrength;
+	}
+	
+	return result;
+}
+
+-(float)sharpeningStrength {
+	return _sharpeningStrength;
+}
+
+-(void)sharpeningStrength:(float)value {
+	_sharpeningStrength = value;
+	if (_sharpeningEnabled) {
+		[_wrapper lock];
+		[[_wrapper pipeline] setSharpeningPower:value];
+		[_wrapper unlock];
+	}
+}
+
+- (nullable FlutterError*)setColorFilterMode:(NSString *)modeName {
+	const ColorFilterMode mode = mapColorFilterName(modeName);
+	if (mode == _colorFilterMode) {
+		return nil;
+	}
+	
+	VideoEffectsSDKPipelineWrapper* wrapper = [self provideWrapper];
+	
+	[wrapper lock];
+	FlutterError* error = [self setColorFilterMode:mode wrapper:wrapper];
+	[wrapper unlock];
+	
+	[self ensureWrapper];
+	
+	return error;
+}
+
+- (nullable FlutterError*)setColorFilterMode:(ColorFilterMode)mode wrapper:(nonnull VideoEffectsSDKPipelineWrapper*)wrapper {
+	TSVBPipelineError errorCode = TSVBPipelineErrorOk;
+	switch (mode){
+		case noColorFilter: {
+			[wrapper.pipeline disableLowLightAdjustment];
+			[wrapper.pipeline disableColorCorrection];
+			_colorFilterMode = noColorFilter;
+		} break;
+		case mlColorCorrection: {
+			errorCode = [wrapper.pipeline enableColorCorrection];
+			if (TSVBPipelineErrorOk == errorCode) {
+				[wrapper.pipeline disableLowLightAdjustment];
+				wrapper.pipeline.colorCorrectionPower = _colorFilterStrength;
+				_colorFilterMode = mlColorCorrection;
+			}
+		} break;
+		case colorGrading: {
+			if (nil == _colorGradingReference) {
+				return [FlutterError
+						errorWithCode:@"setColorCorrectionMode failed"
+						message:@"Error: Cannot activate color grading until reference image is set"
+						details:nil
+				];
+			}
+			errorCode =
+				[wrapper.pipeline enableColorCorrectionWithReferance:_colorGradingReference];
+			if (TSVBPipelineErrorOk == errorCode) {
+				[wrapper.pipeline disableLowLightAdjustment];
+				wrapper.pipeline.colorCorrectionPower = _colorFilterStrength;
+				_colorFilterMode = mlColorCorrection;
+			}
+		} break;
+		case lowLight: {
+			errorCode = [wrapper.pipeline enableLowLightAdjustment];
+			if (TSVBPipelineErrorOk == errorCode) {
+				[wrapper.pipeline disableColorCorrection];
+				wrapper.pipeline.lowLightAdjustmentPower = _colorFilterStrength;
+				_colorFilterMode = lowLight;
+			}
+		} break;
+	}
+	
+	return [self flutterErrorWithPipelineError:errorCode method:@"setColorFilterMode"];
+}
+
+-(id<TSVBFrame>)colorGradingReference {
+	return _colorGradingReference;
+}
+
+-(void)setColorGradingReference:(id<TSVBFrame>)colorGradingReference {
+	_colorGradingReference = colorGradingReference;
+	if (colorGrading == _colorFilterMode) {
+		[_wrapper lock];
+		[[_wrapper pipeline] enableColorCorrectionWithReferance:colorGradingReference];
+		[_wrapper unlock];
+	}
+}
+
+-(VideoEffectsSDKPipelineWrapper*)provideWrapper{
+	if (nil == _wrapper) {
+		id<TSVBPipeline> pipeline = [_sdkFactory newPipeline];
+		_wrapper = [[VideoEffectsSDKPipelineWrapper alloc] initWithSDKPipeline:pipeline frameFactory:_frameFactory];
+	}
+	
+	return _wrapper;
+}
+
+-(void)ensureWrapper {
+	if ([self hasEnabledFeatures]) {
+		if (!_isInserted && (nil != _wrapper)) {
+			_wrapper.sourceIsCamera = _adapter.sourceIsCamera;
+			[_adapter addProcessing:_wrapper];
+			_isInserted = true;
+		}
+	}
+	else {
+		if (_isInserted) {
+			[_adapter removeProcessing:_wrapper];
+			_isInserted = false;
+		}
+		_wrapper = nil;
+	}
+}
+
+-(bool)hasEnabledFeatures {
+	return 
+		_blurEnabled ||
+		_replaceEnabled ||
+		_removeEnabled ||
+		_beautificationEnabled ||
+		_zoomEnabled ||
+		_sharpeningEnabled ||
+		(noColorFilter != _colorFilterMode);
+}
+
+-(id<TSVBFrame>)defaultBackground {
+	return [SDKFrameFactoryHelper solidFrameWithRed:0 green:0.8 blue:0 factory:_frameFactory];
+}
+
+-(FlutterError*)flutterErrorWithPipelineError:(TSVBPipelineError)error method:(NSString*)method {
+	if (TSVBPipelineErrorOk == error) {
+		return nil;
+	}
+	
+	NSString* errorText = nil;
+	switch (error) {
+		case TSVBPipelineErrorInvalidArgument:
+			errorText = @"Error: Passed one or more invalid arguments";
+			break;
+			
+		// Just to prevent warning
+		case TSVBPipelineErrorOk:
+		case TSVBPipelineErrorNoFeaturesEnabled:
+			break;
+			
+		case TSVBPipelineErrorResourceAllocationError:
+			errorText = @"Error: Resource allocation error";
+			break;
+			
+		case TSVBPipelineErrorEngineInitializationError:
+			errorText = @"Error: Failed to initialize engine";
+			break;
+	}
+	
+	return [FlutterError errorWithCode:[NSString stringWithFormat:@"%@ failed", method]
+							  message:errorText
+								details:nil];
+}
+
+@end
+
+@implementation VideoEffectsSDKContext
+{
+	enum AuthState _authState;
+	TSVBSDKFactory* _sdkFactory;
+	id<TSVBFrameFactory> _frameFactory;
+}
+
+-(instancetype)init {
+	self = [super init];
+	if (self) {
+		_authState = AuthStateNotAuthorized;
+		_sdkFactory = [TSVBSDKFactory new];
+		_frameFactory = [_sdkFactory newFrameFactory];
+	}
+	
+	return self;
+}
+
+@synthesize sdkFactory = _sdkFactory;
+@synthesize frameFactory = _frameFactory;
+
+@synthesize authState = _authState;
+
+- (VideoEffectsSDKPipelineController *)newPipelineControllerWithAdapter:(nonnull VideoProcessingAdapter *)adapter {
+	return [[VideoEffectsSDKPipelineController alloc] initWithSDKFactory:_sdkFactory frameFactory:_frameFactory adapter:adapter];
+}
+
+@end
+
+@implementation SDKFrameFactoryHelper
+
++ (id<TSVBFrame>)solidFrameWithRed:(float)r green:(float)g blue:(float)b factory:(id<TSVBFrameFactory>)factory {
+	uint32_t pixel =
+		(MIN(MAX((int)(r * 255), 0), 255)      ) |
+		(MIN(MAX((int)(g * 255), 0), 255) << 8 ) |
+		(MIN(MAX((int)(b * 255), 0), 255) << 16) |
+		(0xff << 24);
+	return [factory newFrameWithFormat:TSVBFrameFormatRgba32
+										data:&pixel
+								bytesPerLine:sizeof(pixel)
+									   width:1
+									  height:1
+									makeCopy:true];
+}
+
+@end
+
+NSString* nameOfAuthStatus(TSVBAuthStatus status) {
+	switch (status) {
+		case TSVBAuthStatusActive:
+			return @"ACTIVE";
+			
+		case TSVBAuthStatusExpired:
+			return @"EXPIRED";
+			
+		case TSVBAuthStatusInactive:
+			return @"INACTIVE";
+			
+		default:
+			return @"ERROR";
+	}
+}
diff --git a/common/darwin/Classes/VideoEffectsSDKExts.h b/common/darwin/Classes/VideoEffectsSDKExts.h
new file mode 100644
index 0000000..9666fe9
--- /dev/null
+++ b/common/darwin/Classes/VideoEffectsSDKExts.h
@@ -0,0 +1,15 @@
+#import "LocalVideoTrack.h"
+
+@class VideoEffectsSDKPipelineController;
+
+@interface LocalVideoTrack (VideoEffectsSDK)
+
+@property(nonatomic, strong, nullable) VideoEffectsSDKPipelineController* sdkPipelineController;
+
+@end
+
+@interface VideoProcessingAdapter (VideoEffectsSDK)
+
+@property(nonatomic) bool sourceIsCamera;
+
+@end
diff --git a/common/darwin/Classes/VideoEffectsSDKExts.m b/common/darwin/Classes/VideoEffectsSDKExts.m
new file mode 100644
index 0000000..6e9a9c1
--- /dev/null
+++ b/common/darwin/Classes/VideoEffectsSDKExts.m
@@ -0,0 +1,38 @@
+#import "VideoEffectsSDKExts.h"
+#import <objc/runtime.h>
+
+@implementation LocalVideoTrack (VideoEffectsSDK)
+
+- (VideoEffectsSDKPipelineController*)sdkPipelineController {
+	return objc_getAssociatedObject(self, _cmd);
+}
+
+- (void)setSdkPipelineController:(id)controller {
+	objc_setAssociatedObject(
+		self,
+		@selector(sdkPipelineController),
+		controller,
+		OBJC_ASSOCIATION_RETAIN_NONATOMIC
+	);
+}
+
+@end
+
+@implementation VideoProcessingAdapter (VideoEffectsSDK)
+
+- (bool)sourceIsCamera {
+	NSNumber* num = objc_getAssociatedObject(self, _cmd);
+	return [num boolValue];
+}
+
+- (void)setSourceIsCamera:(bool)value {
+	NSNumber* newNum = value? [NSNumber numberWithBool:value] : nil;
+	objc_setAssociatedObject(
+		self,
+		@selector(sourceIsCamera),
+		newNum,
+		OBJC_ASSOCIATION_RETAIN_NONATOMIC
+	);
+}
+
+@end
diff --git a/example/android/app/build.gradle b/example/android/app/build.gradle
index 678af19..9ccec5c 100644
--- a/example/android/app/build.gradle
+++ b/example/android/app/build.gradle
@@ -42,3 +42,16 @@ android {
 flutter {
     source = "../.."
 }
+
+dependencies {
+    // CameraX
+    implementation "androidx.camera:camera-core:1.3.0-alpha04"
+    implementation "androidx.camera:camera-camera2:1.3.0-alpha04"
+    implementation "androidx.camera:camera-lifecycle:1.3.0-alpha04"
+    implementation "androidx.camera:camera-view:1.3.0-alpha04"
+
+    //sdk dependency
+    implementation 'com.google.flogger:flogger:0.6'
+    implementation 'com.google.flogger:flogger-system-backend:0.6'
+    implementation 'com.google.guava:guava:27.0.1-android'
+}
diff --git a/example/lib/src/get_user_media_sample.dart b/example/lib/src/get_user_media_sample.dart
index 9c2dea8..de15535 100644
--- a/example/lib/src/get_user_media_sample.dart
+++ b/example/lib/src/get_user_media_sample.dart
@@ -60,13 +60,13 @@ class _GetUserMediaSampleState extends State<GetUserMediaSample> {
     final mediaConstraints = <String, dynamic>{
       'audio': false,
       'video': {
-        'mandatory': {
-          'minWidth':
-              '640', // Provide your own width, height and frame rate here
+        'mandatory': { // Provide your own width, height and frame rate here
+          'minWidth': '640',
           'minHeight': '480',
           'minFrameRate': '30',
         },
         'facingMode': 'user',
+        'effectsSdkRequired': true,
         'optional': [],
       }
     };
@@ -76,6 +76,21 @@ class _GetUserMediaSampleState extends State<GetUserMediaSample> {
       _mediaDevicesList = await navigator.mediaDevices.enumerateDevices();
       _localStream = stream;
       _localRenderer.srcObject = _localStream;
+      var status = await Helper.auth(stream.getVideoTracks().first, 'YOUR_CUSTOMER_ID');
+      switch (status) {
+        case AuthStatus.active:
+          Helper.setEffectsSdkPipelineMode(stream.getVideoTracks().first, PipelineMode.blur);
+          Helper.setEffectsSdkBlurPower(stream.getVideoTracks().first, 0.6);
+        case AuthStatus.expired:
+          // TODO: Handle this case.
+        case AuthStatus.inactive:
+          // TODO: Handle this case.
+        case AuthStatus.unavailable:
+          // TODO: Handle this case.
+        case AuthStatus.error:
+          // TODO: Handle this case.
+      }
+
     } catch (e) {
       print(e.toString());
     }
diff --git a/github_patch_repository/readme.md b/github_patch_repository/readme.md
new file mode 100644
index 0000000..06bed96
--- /dev/null
+++ b/github_patch_repository/readme.md
@@ -0,0 +1,147 @@
+# Flutter EffectsSDK integration
+
+Tested for **flutter-webrtc v0.14.0**
+
+## Instructions
+
+Clone [flutter WebRTC](https://github.com/flutter-webrtc/flutter-webrtc) repository
+```sh
+git clone https://github.com/flutter-webrtc/flutter-webrtc.git
+```
+
+Go to the cloned dir.
+```sh 
+cd flutter-webrtc
+```
+
+[Optional] Switch to the required version
+```sh
+git switch -d v0.14.0
+```
+_For other versions, conflicts may occur._
+
+Apply the [patch](flutter-webrtc-effects-sdk.patch) to the flutter-webrtc repo
+```sh
+curl https://raw.githubusercontent.com/EffectsSDK/flutter-webrtc-integration/refs/heads/main/flutter-webrtc-effects-sdk.patch | git apply
+```
+_You can mannually download the [patch](flutter-webrtc-effects-sdk.patch) and apply it with git apply path/to/patch_
+
+Add flutter-webrtc as dependency to your project by path
+
+pubspec.yaml
+```yaml
+dependencies:
+  flutter_webrtc:
+    path: path/to/flutter-webrtc
+```
+
+### Android
+
+For android platform additionally you need:
+
+1. Download the Video Effects SDK release for Android
+2. Add the SDK as a WebRTC dependency by placing it in: **path/to/flutter-webrtc/android/libs/**
+
+## How to use
+
+1. Add effectsSdkRequired flag to your getUserMedia request
+
+```dart
+
+final mediaConstraints = <String, dynamic>{
+  'audio': false,
+  'video': {
+    'mandatory': {
+      'minWidth': '640',
+      'minHeight': '480',
+      'minFrameRate': '30',
+    },
+    'facingMode': 'user',
+    'effectsSdkRequired': true,
+    'optional': [],
+  }
+};
+var stream = await navigator.mediaDevices.getUserMedia(mediaConstraints);
+```
+
+2. Call EffectsSDK methods by using WebRTC Helper
+
+```dart
+
+var status = await Helper.auth(stream.getVideoTracks().first, 'YOUR_CUSTOMER_ID');
+switch (status) {
+    case AuthStatus.active:
+    await Helper.setEffectsSdkPipelineMode(stream.getVideoTracks().first, PipelineMode.blur);
+    await Helper.setEffectsSdkBlurPower(stream.getVideoTracks().first, 0.6);
+    case AuthStatus.expired:
+    // TODO: Handle this case.
+    case AuthStatus.inactive:
+    // TODO: Handle this case.
+    case AuthStatus.unavailable:
+    // TODO: Handle this case.
+}
+```
+
+## EffectsSDK methods
+
+Check platform specifications:
+
+1. [iOS](https://github.com/EffectsSDK/swift-video-effects-sdk)
+2. [android](https://github.com/EffectsSDK/android-integration-sample)
+
+### Effects SDK Image
+
+Image proxy for iOS/android compatibility.
+
+Can be created from:
+
+1. raw data
+2. file
+3. encoded data
+4. rgb color
+
+### Color correction options
+
+4 different methods are supported:
+
+1. Color correction - use ML model for color correction
+2. Color grading - made color filter by using reference image color scheme
+3. Low light - use ML model for color correction (ust it only in dark places)
+4. Preset - predefined cube lut
+
+
+### Helper methods
+
+| Name                                    | Summary                                                                                                   |
+|-----------------------------------------|-----------------------------------------------------------------------------------------------------------|
+| auth                                    | Future<rtc.AuthStatus> auth(String customerId, {String? apiUrl})<br/>Auth sdk by using customer ID        |
+| localAuth                               | Future<rtc.AuthStatus> localAuth(String localKey)<br/>Auth SDK by using local key                         |
+| getEffectsSdkPipelineMode               | Future<rtc.PipelineMode> getPipelineMode()<br/>Return current background processing mode                  |
+| setEffectsSdkPipelineMode               | void setPipelineMode(rtc.PipelineMode mode)<br/>Set background processing mode                            |
+| setEffectsSdkBlurPower                  | void setBlurPower(double blurPower)<br/>Set blur power                                                    |
+| setEffectsSdkBackgroundImage            | void setBackgroundImage(rtc.EffectsSdkImage data)<br/>Set background image                                |
+| enableEffectsSdkBeautification          | void enableBeautification(bool enable)<br/>Enable beautification feature                                  |
+| isEffectsSdkBeautificationEnabled       | Future<bool> isBeautificationEnabled()<br/>Return true if beautification enabled                          |
+| setEffectsSdkBeautificationPower        | void setBeautificationPower(double power)<br/>Set beautification power                                    |
+| getEffectsSdkZoomLevel                  | Future<double> getZoomLevel()<br/>Get current zoom level                                                  |
+| setEffectsSdkZoomLevel                  | void setZoomLevel(double zoomLevel)<br/>Set zoom level                                                    |
+| enableEffectsSdkSharpening              | void enableSharpening(bool enable)<br/>Enable sharpening mode                                             |
+| getEffectsSdkSharpeningStrength         | Future<double> getSharpeningStrength()<br/>Return current sharpening power                                |
+| setEffectsSdkSharpeningStrength         | void setSharpeningStrength(double strength)<br/>Set sharpening power                                      |
+| setEffectsSdkColorCorrectionMode        | void setColorCorrectionMode(rtc.ColorCorrectionMode colorCorrectionMode)<br/>Set color correction mode    |
+| setEffectsSdkColorFilterStrength        | void setColorFilterStrength(double strength)<br/>Set color filter strength                                |
+| setEffectsSdkColorGradingReferenceImage | void setColorGradingReferenceImage(rtc.EffectsSdkImage data)<br/>Set reference image for color correction |
+
+
+## Technical details
+
+Effects SDK included by using custom CameraVideoCapturer instance for Effects SDK camera pipeline(
+android).
+You can modify our solution as you need or try another way for integration (for example with custom
+VideoProcessor).
+Also you can replace CameraPipeline to lite version of it.
+
+## Additional links
+
+1. Platform documentation ([iOS](https://effectssdk.ai/sdk/ios/documentation/tsvb/), [android](https://github.com/EffectsSDK/android-integration-sample))
+2. Effects SDK [site](https://effectssdk.ai/)
diff --git a/ios/Classes/VideoEffectsSDKContext.h b/ios/Classes/VideoEffectsSDKContext.h
new file mode 120000
index 0000000..4c0ecc0
--- /dev/null
+++ b/ios/Classes/VideoEffectsSDKContext.h
@@ -0,0 +1 @@
+../../common/darwin/Classes/VideoEffectsSDKContext.h
\ No newline at end of file
diff --git a/ios/Classes/VideoEffectsSDKContext.m b/ios/Classes/VideoEffectsSDKContext.m
new file mode 120000
index 0000000..c8b7f44
--- /dev/null
+++ b/ios/Classes/VideoEffectsSDKContext.m
@@ -0,0 +1 @@
+../../common/darwin/Classes/VideoEffectsSDKContext.m
\ No newline at end of file
diff --git a/ios/Classes/VideoEffectsSDKExts.h b/ios/Classes/VideoEffectsSDKExts.h
new file mode 120000
index 0000000..d3d5b7a
--- /dev/null
+++ b/ios/Classes/VideoEffectsSDKExts.h
@@ -0,0 +1 @@
+../../common/darwin/classes/VideoEffectsSDKExts.h
\ No newline at end of file
diff --git a/ios/Classes/VideoEffectsSDKExts.m b/ios/Classes/VideoEffectsSDKExts.m
new file mode 120000
index 0000000..212349e
--- /dev/null
+++ b/ios/Classes/VideoEffectsSDKExts.m
@@ -0,0 +1 @@
+../../common/darwin/classes/VideoEffectsSDKExts.m
\ No newline at end of file
diff --git a/ios/flutter_webrtc.podspec b/ios/flutter_webrtc.podspec
index 778368a..7781cfc 100644
--- a/ios/flutter_webrtc.podspec
+++ b/ios/flutter_webrtc.podspec
@@ -16,6 +16,7 @@ A new flutter plugin project.
   s.public_header_files = 'Classes/**/*.h'
   s.dependency 'Flutter'
   s.dependency 'WebRTC-SDK', '125.6422.07'
+  s.dependency 'VideoEffectsSDK', '2.5.1'
   s.ios.deployment_target = '13.0'
   s.static_framework = true
   s.pod_target_xcconfig = {
diff --git a/lib/flutter_webrtc.dart b/lib/flutter_webrtc.dart
index b7dd3a8..8ab02b2 100644
--- a/lib/flutter_webrtc.dart
+++ b/lib/flutter_webrtc.dart
@@ -3,6 +3,8 @@ library flutter_webrtc;
 export 'package:webrtc_interface/webrtc_interface.dart'
     hide MediaDevices, MediaRecorder, Navigator;
 
+export 'src/effects_sdk_constants.dart';
+export 'src/effects_sdk_image.dart' show EffectsSdkImage, RawImageFormat;
 export 'src/helper.dart';
 export 'src/desktop_capturer.dart';
 export 'src/media_devices.dart';
diff --git a/lib/src/effects_sdk_constants.dart b/lib/src/effects_sdk_constants.dart
new file mode 100644
index 0000000..561f231
--- /dev/null
+++ b/lib/src/effects_sdk_constants.dart
@@ -0,0 +1,111 @@
+/// Authentication statuses for the SDK license.
+enum AuthStatus {
+  /// License is active and valid
+  active,
+
+  /// License has expired
+  expired,
+
+  /// License is not activated
+  inactive,
+
+  /// Authentication service unavailable
+  unavailable,
+
+  /// General authentication error
+  error,
+}
+
+/// Video background processing modes
+enum PipelineMode {
+  /// Remove background completely
+  remove,
+
+  /// Replace background with custom image/video
+  replace,
+
+  /// Apply background blur effect
+  blur,
+
+  /// Disable all background processing
+  noEffects,
+}
+
+/// Color processing modes for video
+enum ColorCorrectionMode {
+  /// No color adjustments applied
+  noFilterMode,
+
+  /// Automatic color correction and white balance
+  colorCorrectionMode,
+
+  /// Manual color grading controls
+  colorGradingMode,
+
+  /// Apply predefined color presets
+  presetMode,
+
+  /// Low light environment optimization
+  lowLightMode,
+}
+
+/// Converts Java Platform enum string to [AuthStatus] value.
+///
+/// Supported values:
+/// - 'ACTIVE' → [AuthStatus.active]
+/// - 'INACTIVE' → [AuthStatus.inactive]
+/// - 'EXPIRED' → [AuthStatus.expired]
+/// - 'UNAVAILABLE' → [AuthStatus.unavailable]
+/// - 'ERROR' → [AuthStatus.error]
+///
+/// Throws [Exception] if unknown value is passed.
+AuthStatus parseJavaAuthStatus(String javaEnumValue) {
+  switch (javaEnumValue) {
+    case 'ACTIVE': return AuthStatus.active;
+    case 'INACTIVE': return AuthStatus.inactive;
+    case 'EXPIRED': return AuthStatus.expired;
+    case 'UNAVAILABLE': return AuthStatus.unavailable;
+    case 'ERROR': return AuthStatus.error;
+    default: throw Exception('Unknown enum value: $javaEnumValue');
+  }
+}
+
+/// Converts Java Platform enum string to [PipelineMode] value.
+///
+/// Supported values:
+/// - 'REMOVE' → [PipelineMode.remove]
+/// - 'REPLACE' → [PipelineMode.replace]
+/// - 'BLUR' → [PipelineMode.blur]
+/// - 'NO_EFFECTS' → [PipelineMode.noEffects]
+///
+/// Throws [Exception] if unknown value is passed.
+PipelineMode parseJavaPipelineMode(String javaEnumValue) {
+  switch (javaEnumValue) {
+    case 'REMOVE': return PipelineMode.remove;
+    case 'REPLACE': return PipelineMode.replace;
+    case 'BLUR': return PipelineMode.blur;
+    case 'NO_EFFECTS': return PipelineMode.noEffects;
+    default: throw Exception('Unknown enum value: $javaEnumValue');
+  }
+}
+
+/// Converts Java Platform enum string to [ColorCorrectionMode] value.
+///
+/// Supported values:
+/// - 'NO_FILTER_MODE' → [ColorCorrectionMode.noFilterMode]
+/// - 'COLOR_CORRECTION_MODE' → [ColorCorrectionMode.colorCorrectionMode]
+/// - 'COLOR_GRADING_MODE' → [ColorCorrectionMode.colorGradingMode]
+/// - 'PRESET_MODE' → [ColorCorrectionMode.presetMode]
+/// - 'LOW_LIGHT_MODE' → [ColorCorrectionMode.lowLightMode]
+///
+/// Throws [Exception] if unknown value is passed.
+ColorCorrectionMode parseJavaColorCorrectionMode(String javaEnumValue) {
+  switch (javaEnumValue) {
+    case 'NO_FILTER_MODE': return ColorCorrectionMode.noFilterMode;
+    case 'COLOR_CORRECTION_MODE': return ColorCorrectionMode.colorCorrectionMode;
+    case 'COLOR_GRADING_MODE': return ColorCorrectionMode.colorGradingMode;
+    case 'PRESET_MODE': return ColorCorrectionMode.presetMode;
+    case 'LOW_LIGHT_MODE': return ColorCorrectionMode.lowLightMode;
+    default: throw Exception('Unknown enum value: $javaEnumValue');
+  }
+}
\ No newline at end of file
diff --git a/lib/src/effects_sdk_image.dart b/lib/src/effects_sdk_image.dart
new file mode 100644
index 0000000..68191b7
--- /dev/null
+++ b/lib/src/effects_sdk_image.dart
@@ -0,0 +1,146 @@
+import 'dart:typed_data';
+import 'package:flutter/widgets.dart';
+
+/// Types of image sources supported by the effects SDK.
+sealed class ImageSource {}
+
+/// Pixel format for raw image data.
+///
+/// Currently only RGBA format is supported (4 bytes per pixel).
+enum RawImageFormat {
+  /// 4 bytes per pixel in Red-Green-Blue-Alpha order.
+  rgba
+}
+
+/// Raw pixel data image representation.
+///
+/// Used for direct pixel manipulation with format, dimensions and stride.
+class RawImage extends ImageSource {
+  /// Creates a raw image from pixel data.
+  ///
+  /// - [data]: Raw pixel bytes in specified format
+  /// - [format]: Pixel format (currently only [RawImageFormat.rgba])
+  /// - [width]: Image width in pixels
+  /// - [height]: Image height in pixels
+  /// - [bytesPerRow]: Number of bytes per row (stride). Defaults to
+  ///   `width * 4` if not specified (for RGBA format).
+  RawImage({
+    required this.data,
+    required this.format,
+    required this.width,
+    required this.height,
+    required this.bytesPerRow,
+  });
+
+  /// Raw pixel bytes.
+  final Uint8List data;
+
+  /// Pixel format specification.
+  final RawImageFormat format;
+
+  /// Image width in pixels.
+  final int width;
+
+  /// Image height in pixels.
+  final int height;
+
+  /// Number of bytes per row (stride).
+  final int bytesPerRow;
+}
+
+/// Image loaded from a file path.
+class FilePathImage extends ImageSource {
+  /// Creates an image from a local file path.
+  ///
+  /// - [path]: Filesystem path to the image (e.g. 'assets/background.jpg')
+  FilePathImage(this.path);
+
+  /// Local filesystem path to the image file.
+  final String path;
+}
+
+/// Encoded image data (e.g. PNG/JPEG).
+class EncodedImageData extends ImageSource {
+  /// Creates an image from encoded bytes.
+  ///
+  /// - [data]: Compressed image bytes in supported format
+  EncodedImageData(this.data);
+
+  /// Encoded image bytes.
+  final Uint8List data;
+}
+
+/// Solid color image defined by RGB components.
+class SolidRGBImage extends ImageSource {
+  /// Creates a solid color image.
+  ///
+  /// All values should be in 0.0-1.0 range.
+  ///
+  /// - [r]: Red channel (0.0 to 1.0)
+  /// - [g]: Green channel (0.0 to 1.0)
+  /// - [b]: Blue channel (0.0 to 1.0)
+  SolidRGBImage({
+    required this.r,
+    required this.g,
+    required this.b,
+  });
+
+  /// Red channel value.
+  final double r;
+
+  /// Green channel value.
+  final double g;
+
+  /// Blue channel value.
+  final double b;
+}
+
+/// Container for image data used by the effects SDK.
+class EffectsSdkImage {
+  /// The source of the image data.
+  final ImageSource source;
+
+  /// Creates image from raw pixel data.
+  ///
+  /// - [data]: Raw pixel bytes in specified format
+  /// - [format]: Pixel format (must be [RawImageFormat.rgba])
+  /// - [width]: Image width in pixels
+  /// - [height]: Image height in pixels
+  /// - [bytesPerRow]: Optional stride. Defaults to `width * 4`.
+  EffectsSdkImage.fromRaw({
+    required Uint8List data,
+    required RawImageFormat format,
+    required int width,
+    required int height,
+    int bytesPerRow = 0,
+  }) : source = RawImage(
+    data: data,
+    format: format,
+    width: width,
+    height: height,
+    bytesPerRow: (bytesPerRow > 0) ? bytesPerRow : width * 4,
+  );
+
+  /// Creates image from a local file path.
+  ///
+  /// - [filepath]: Path to image file (JPEG/PNG supported)
+  EffectsSdkImage.fromPath(String filepath) : source = FilePathImage(filepath);
+
+  /// Creates image from encoded bytes.
+  ///
+  /// - [encoded]: Compressed image data (JPEG/PNG supported)
+  EffectsSdkImage.fromEncoded(Uint8List encoded) : source = EncodedImageData(encoded);
+
+  /// Creates solid color image from RGB values.
+  ///
+  /// All values should be in 0.0-1.0 range.
+  ///
+  /// - [r]: Red component (0.0 to 1.0)
+  /// - [g]: Green component (0.0 to 1.0)
+  /// - [b]: Blue component (0.0 to 1.0)
+  EffectsSdkImage.fromRGB({
+    required double r,
+    required double g,
+    required double b,
+  }) : source = SolidRGBImage(r: r, g: g, b: b);
+}
\ No newline at end of file
diff --git a/lib/src/helper.dart b/lib/src/helper.dart
index 6f1e966..0a6007b 100644
--- a/lib/src/helper.dart
+++ b/lib/src/helper.dart
@@ -1,6 +1,7 @@
 import 'dart:math';
 
 import 'package:flutter/foundation.dart';
+import 'package:flutter_webrtc/src/effects_sdk_image.dart';
 
 import '../flutter_webrtc.dart';
 
@@ -179,4 +180,283 @@ class Helper {
       throw Exception('requestCapturePermission only support for Android');
     }
   }
+
+  /// Effects SDK control methods. Check effectsSDK docs here:
+  /// iOS: *link*
+  /// android: *link*
+
+  /// Gets the current background processing mode for a media track.
+  ///
+  /// - [mediaStreamTrack]: The target media track
+  /// - Returns: Current [PipelineMode]
+  /// - Throws: [Exception] if native method fails or returns unknown value
+  static Future<PipelineMode> getEffectsSdkPipelineMode(
+      MediaStreamTrack mediaStreamTrack) async {
+    String mode = await WebRTC.invokeMethod(
+      'getPipelineMode',
+      <String, dynamic>{'trackId': mediaStreamTrack.id},
+    );
+    return parseJavaPipelineMode(mode);
+  }
+
+  /// Authenticates SDK using remote service.
+  ///
+  /// - [mediaStreamTrack]: Associated media track
+  /// - [customerKey]: License key for authentication
+  /// - [apiUrl]: Optional custom authentication endpoint
+  /// - Returns: [AuthStatus] indicating authentication result
+  /// - Throws: Platform exceptions for communication errors
+  static Future<AuthStatus> auth(
+      MediaStreamTrack mediaStreamTrack, String customerKey,
+      {String? apiUrl}) async {
+    String status = await WebRTC.invokeMethod(
+      'auth',
+      <String, dynamic>{
+        'trackId': mediaStreamTrack.id,
+        'customerKey': customerKey,
+        'apiUrl': apiUrl
+      },
+    );
+    return parseJavaAuthStatus(status);
+  }
+
+  /// Authenticates SDK using local license validation.
+  ///
+  /// - [mediaStreamTrack]: Associated media track
+  /// - [localKey]: Locally stored license key
+  /// - Returns: [AuthStatus] indicating authentication result
+  static Future<AuthStatus> localAuth(
+    MediaStreamTrack mediaStreamTrack,
+    String localKey
+  ) async {
+    String status = await WebRTC.invokeMethod(
+      'localAuth',
+      <String, dynamic>{'trackId': mediaStreamTrack.id, 'localKey': localKey},
+    );
+    return parseJavaAuthStatus(status);
+  }
+
+  /// Sets background processing mode for a media track.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [pipelineMode]: New processing mode to apply
+  static Future<void> setEffectsSdkPipelineMode(
+      MediaStreamTrack mediaStreamTrack, PipelineMode pipelineMode) async {
+    await WebRTC.invokeMethod(
+      'setPipelineMode',
+      <String, dynamic>{
+        'trackId': mediaStreamTrack.id,
+        'pipelineMode': pipelineMode.toString()
+      },
+    );
+  }
+
+  /// Adjusts blur strength for background blur mode.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [blurPower]: Blur strength (0.0 - 1.0 where 1.0 is maximum blur)
+  static void setEffectsSdkBlurPower(
+      MediaStreamTrack mediaStreamTrack,
+      double blurPower) {
+    WebRTC.invokeMethod(
+      'setBlurPower',
+      <String, dynamic>{'trackId': mediaStreamTrack.id, 'blurPower': blurPower},
+    );
+  }
+
+  /// Sets custom background image for replace mode.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [image]: Image to use as background
+  /// - See also: [EffectsSdkImage] for supported image types
+  static Future<void> setEffectsSdkBackgroundImage(
+    MediaStreamTrack mediaStreamTrack,
+    EffectsSdkImage image,
+  ) async {
+    await WebRTC.invokeMethod(
+      'setBackgroundImage',
+      <String, dynamic>{
+        'trackId': mediaStreamTrack.id,
+        'image': _serializeImage(image)
+      },
+    );
+  }
+
+  /// Enables/disables face beautification effects.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [enable]: true to enable, false to disable
+  static Future<void> enableEffectsSdkBeautification(
+    MediaStreamTrack mediaStreamTrack,
+    bool enable,
+  ) async {
+    await WebRTC.invokeMethod(
+      'enableBeautification',
+      <String, dynamic>{'trackId': mediaStreamTrack.id, 'enable': enable},
+    );
+  }
+
+  /// Checks if beautification is currently enabled.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - Returns: Current enabled status
+  static Future<bool> isEffectsSdkBeautificationEnabled(
+      MediaStreamTrack mediaStreamTrack) async {
+    return await WebRTC.invokeMethod(
+      'isBeautificationEnabled',
+      <String, dynamic>{'trackId': mediaStreamTrack.id},
+    );
+  }
+
+  /// Adjusts beautification effect strength.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [power]: Effect strength (0.0 - 1.0)
+  static void setEffectsSdkBeautificationPower(
+    MediaStreamTrack mediaStreamTrack,
+    double power,
+  ) {
+    WebRTC.invokeMethod(
+      'setBeautificationPower',
+      <String, dynamic>{
+        'trackId': mediaStreamTrack.id,
+        'beautificationPower': power
+      },
+    );
+  }
+
+  /// Gets current digital zoom level.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - Returns: Current zoom level (1.0 = no zoom)
+  static Future<double> getEffectsSdkZoomLevel(
+      MediaStreamTrack mediaStreamTrack) async {
+    return await WebRTC.invokeMethod(
+      'getZoomLevel',
+      <String, dynamic>{'trackId': mediaStreamTrack.id},
+    );
+  }
+
+  /// Sets digital zoom level.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [zoomLevel]: New zoom level (≥1.0)
+  static Future<void> setEffectsSdkZoomLevel(
+    MediaStreamTrack mediaStreamTrack,
+    double zoomLevel,
+  ) async {
+    await WebRTC.invokeMethod(
+      'setZoomLevel',
+      <String, dynamic>{'trackId': mediaStreamTrack.id, 'zoomLevel': zoomLevel},
+    );
+  }
+
+  /// Enables/disables image sharpening.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [enable]: true to enable, false to disable
+  static void enableEffectsSdkSharpening(
+    MediaStreamTrack mediaStreamTrack,
+    bool enable,
+  ) {
+    WebRTC.invokeMethod(
+      'enableSharpening',
+      <String, dynamic>{'trackId': mediaStreamTrack.id, 'enable': enable},
+    );
+  }
+
+  /// Gets current sharpening strength.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - Returns: Current sharpening strength (0.0 - 1.0)
+  static Future<double> getEffectsSdkSharpeningStrength(
+      MediaStreamTrack mediaStreamTrack) async {
+    return await WebRTC.invokeMethod(
+      'getSharpeningStrength',
+      <String, dynamic>{'trackId': mediaStreamTrack.id},
+    );
+  }
+
+  /// Adjusts image sharpening strength.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [strength]: New sharpening strength (0.0 - 1.0)
+  static void setEffectsSdkSharpeningStrength(
+    MediaStreamTrack mediaStreamTrack,
+    double strength,
+  ) {
+    WebRTC.invokeMethod(
+      'setSharpeningStrength',
+      <String, dynamic>{'trackId': mediaStreamTrack.id, 'strength': strength},
+    );
+  }
+
+  /// Sets color correction processing mode.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [colorCorrectionMode]: New color processing mode
+  static void setEffectsSdkColorCorrectionMode(
+    MediaStreamTrack mediaStreamTrack,
+    ColorCorrectionMode colorCorrectionMode,
+  ) {
+    WebRTC.invokeMethod(
+      'setColorCorrectionMode',
+      <String, dynamic>{
+        'trackId': mediaStreamTrack.id,
+        'colorCorrectionMode': colorCorrectionMode.toString()
+      },
+    );
+  }
+
+  /// Adjusts color filter strength.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [strength]: Filter intensity (0.0 - 1.0)
+  static void setEffectsSdkColorFilterStrength(
+    MediaStreamTrack mediaStreamTrack,
+    double strength,
+  ) {
+    WebRTC.invokeMethod(
+      'setColorFilterStrength',
+      <String, dynamic>{'trackId': mediaStreamTrack.id, 'strength': strength},
+    );
+  }
+
+  /// Sets reference image for color grading mode.
+  ///
+  /// - [mediaStreamTrack]: Target media track
+  /// - [image]: Reference image for color matching
+  static void setEffectsSdkColorGradingReferenceImage(
+    MediaStreamTrack mediaStreamTrack,
+    EffectsSdkImage image,
+  ) {
+    WebRTC.invokeMethod(
+      'setColorGradingReferenceImage',
+      <String, dynamic>{
+        'trackId': mediaStreamTrack.id,
+        'reference': _serializeImage(image)
+      },
+    );
+  }
+
+  /// Serializes [EffectsSdkImage] to platform-specific format.
+  static Map<String, dynamic> _serializeImage(EffectsSdkImage image) {
+    switch (image.source) {
+      case FilePathImage s:
+        return <String, dynamic>{"type": "filepath", "path": s.path};
+      case EncodedImageData s:
+        return <String, dynamic>{"type": "encoded", "data": s.data};
+      case SolidRGBImage(r: final r, g: final g, b: final b):
+        return <String, dynamic>{"type": "rgb", "r": r, "g": g, "b": b};
+      case RawImage s:
+        return <String, dynamic>{
+          "type": "raw",
+          "data": s.data,
+          "format": s.format.name,
+          "width": s.width,
+          "height": s.height,
+          "stride": s.bytesPerRow
+        };
+    }
+  }
 }
