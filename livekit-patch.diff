diff --git a/example/android/.gitignore b/example/android/.gitignore
index 0a741cb..fcbd420 100644
--- a/example/android/.gitignore
+++ b/example/android/.gitignore
@@ -4,6 +4,7 @@ gradle-wrapper.jar
 /gradlew
 /gradlew.bat
 /local.properties
+/app/.cxx
 GeneratedPluginRegistrant.java
 
 # Remember to never publicly share your keystore.
diff --git a/example/android/app/build.gradle b/example/android/app/build.gradle
index 9381281..d6b4019 100644
--- a/example/android/app/build.gradle
+++ b/example/android/app/build.gradle
@@ -42,3 +42,16 @@ android {
 flutter {
     source = "../.."
 }
+
+dependencies {
+    // CameraX
+    implementation "androidx.camera:camera-core:1.3.0-alpha04"
+    implementation "androidx.camera:camera-camera2:1.3.0-alpha04"
+    implementation "androidx.camera:camera-lifecycle:1.3.0-alpha04"
+    implementation "androidx.camera:camera-view:1.3.0-alpha04"
+
+    //sdk dependency
+    implementation 'com.google.flogger:flogger:0.6'
+    implementation 'com.google.flogger:flogger-system-backend:0.6'
+    implementation 'com.google.guava:guava:27.0.1-android'
+}
\ No newline at end of file
diff --git a/example/lib/pages/prejoin.dart b/example/lib/pages/prejoin.dart
index a7eccb0..e9f1f3e 100644
--- a/example/lib/pages/prejoin.dart
+++ b/example/lib/pages/prejoin.dart
@@ -50,6 +50,11 @@ class _PreJoinPageState extends State<PreJoinPage> {
 
   bool _busy = false;
   bool _enableVideo = true;
+  bool paused = false;
+  bool _remove = false;
+  bool _blur = true;
+  bool _colorCorrection = false;
+  bool _smartZoom = false;
   bool _enableAudio = true;
   LocalAudioTrack? _audioTrack;
   LocalVideoTrack? _videoTrack;
@@ -109,6 +114,61 @@ class _PreJoinPageState extends State<PreJoinPage> {
     setState(() {});
   }
 
+  Future<void> _pauseVideoTrack(value) async {
+    paused = value;
+    if (paused) {
+      await _videoTrack?.disable();
+    } else {
+      await _videoTrack?.enable();
+    }
+    setState(() {});
+  }
+
+  Future<void> _setReplaceModeSdk(value) async {
+    _remove = value;
+    if (_remove) {
+      _blur = false;
+      _videoTrack!.setPipelineMode(PipelineMode.remove);
+    } else {
+      _videoTrack!.setPipelineMode(PipelineMode.noEffects);
+    }
+    setState(() {});
+  }
+
+  Future<void> _setBlurModeSdk(value) async {
+    _blur = value;
+    if (_blur) {
+      _remove = false;
+      _videoTrack!.setPipelineMode(PipelineMode.blur);
+      _videoTrack!.setBlurPower(0.7);
+    } else {
+      _videoTrack!.setPipelineMode(PipelineMode.noEffects);
+    }
+    setState(() {});
+  }
+
+  Future<void> _setColorCorrectionSdk(value) async {
+    _colorCorrection = value;
+    if (_colorCorrection){
+      _videoTrack!.setColorCorrectionMode(ColorCorrectionMode.colorCorrectionMode);
+      _videoTrack!.setColorFilterStrength(0.5);
+    } else {
+      _videoTrack!.setColorCorrectionMode(ColorCorrectionMode.noFilterMode);
+      _videoTrack!.setColorFilterStrength(0.0);
+    }
+    setState(() {});
+  }
+
+  Future<void> _setSmartZoomSdk(value) async {
+    _smartZoom = value;
+    if (_smartZoom) {
+      _videoTrack!.setZoomLevel(0.5);
+    } else {
+      _videoTrack!.setZoomLevel(0);
+    }
+    setState(() {});
+  }
+
   Future<void> _setEnableAudio(value) async {
     _enableAudio = value;
     if (!_enableAudio) {
@@ -143,12 +203,31 @@ class _PreJoinPageState extends State<PreJoinPage> {
     }
 
     if (_selectedVideoDevice != null) {
-      _videoTrack =
-          await LocalVideoTrack.createCameraTrack(CameraCaptureOptions(
+      _videoTrack = await LocalVideoTrack.createCameraTrack(CameraCaptureOptions(
         deviceId: _selectedVideoDevice!.deviceId,
         params: _selectedVideoParameters,
+        // set effects SDK parameter to true
+        effectsSdkRequired: true,
       ));
       await _videoTrack!.start();
+      // initialize Effects SDK
+      AuthStatus status = await _videoTrack!.auth('YOUR_CUSTOMER_KEY');
+      switch (status){
+        case AuthStatus.active:
+          //Set pipeline options
+          _videoTrack!.setPipelineMode(PipelineMode.blur);
+          _videoTrack!.setBlurPower(0.75);
+          break;
+        case AuthStatus.expired:
+          // TODO: Handle this case as you need.
+          break;
+        case AuthStatus.inactive:
+          // TODO: Handle this case as you need.
+          break;
+        case AuthStatus.unavailable:
+          // TODO: Handle this case as you need.
+          break;
+      }
     }
   }
 
@@ -318,6 +397,71 @@ class _PreJoinPageState extends State<PreJoinPage> {
                         ],
                       ),
                     ),
+                    Padding(
+                      padding: const EdgeInsets.only(bottom: 5),
+                      child: Row(
+                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
+                        children: [
+                          const Text('Pause video:'),
+                          Switch(
+                            value: paused,
+                            onChanged: (value) => _pauseVideoTrack(value),
+                          ),
+                        ],
+                      ),
+                    ),
+                    Padding(
+                      padding: const EdgeInsets.only(bottom: 5),
+                      child: Row(
+                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
+                        children: [
+                          const Text('Remove:'),
+                          Switch(
+                            value: _remove,
+                            onChanged: (value) => _setReplaceModeSdk(value),
+                          ),
+                        ],
+                      ),
+                    ),
+                    Padding(
+                      padding: const EdgeInsets.only(bottom: 5),
+                      child: Row(
+                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
+                        children: [
+                          const Text('Blur:'),
+                          Switch(
+                            value: _blur,
+                            onChanged: (value) => _setBlurModeSdk(value),
+                          ),
+                        ],
+                      ),
+                    ),
+                    Padding(
+                      padding: const EdgeInsets.only(bottom: 5),
+                      child: Row(
+                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
+                        children: [
+                          const Text('SmartZoom:'),
+                          Switch(
+                            value: _smartZoom,
+                            onChanged: (value) => _setSmartZoomSdk(value),
+                          ),
+                        ],
+                      ),
+                    ),
+                    Padding(
+                      padding: const EdgeInsets.only(bottom: 5),
+                      child: Row(
+                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
+                        children: [
+                          const Text('ColorCorrection:'),
+                          Switch(
+                            value: _colorCorrection,
+                            onChanged: (value) => _setColorCorrectionSdk(value),
+                          ),
+                        ],
+                      ),
+                    ),
                     Padding(
                       padding: const EdgeInsets.only(bottom: 25),
                       child: DropdownButtonHideUnderline(
diff --git a/github_patch_repository/livekit-patch.diff b/github_patch_repository/livekit-patch.diff
new file mode 100644
index 0000000..e7efc6d
--- /dev/null
+++ b/github_patch_repository/livekit-patch.diff
@@ -0,0 +1,501 @@
+diff --git a/example/android/.gitignore b/example/android/.gitignore
+index 0a741cb..fcbd420 100644
+--- a/example/android/.gitignore
++++ b/example/android/.gitignore
+@@ -4,6 +4,7 @@ gradle-wrapper.jar
+ /gradlew
+ /gradlew.bat
+ /local.properties
++/app/.cxx
+ GeneratedPluginRegistrant.java
+ 
+ # Remember to never publicly share your keystore.
+diff --git a/example/android/app/build.gradle b/example/android/app/build.gradle
+index 9381281..d6b4019 100644
+--- a/example/android/app/build.gradle
++++ b/example/android/app/build.gradle
+@@ -42,3 +42,16 @@ android {
+ flutter {
+     source = "../.."
+ }
++
++dependencies {
++    // CameraX
++    implementation "androidx.camera:camera-core:1.3.0-alpha04"
++    implementation "androidx.camera:camera-camera2:1.3.0-alpha04"
++    implementation "androidx.camera:camera-lifecycle:1.3.0-alpha04"
++    implementation "androidx.camera:camera-view:1.3.0-alpha04"
++
++    //sdk dependency
++    implementation 'com.google.flogger:flogger:0.6'
++    implementation 'com.google.flogger:flogger-system-backend:0.6'
++    implementation 'com.google.guava:guava:27.0.1-android'
++}
+\ No newline at end of file
+diff --git a/example/lib/pages/prejoin.dart b/example/lib/pages/prejoin.dart
+index a7eccb0..e9f1f3e 100644
+--- a/example/lib/pages/prejoin.dart
++++ b/example/lib/pages/prejoin.dart
+@@ -50,6 +50,11 @@ class _PreJoinPageState extends State<PreJoinPage> {
+ 
+   bool _busy = false;
+   bool _enableVideo = true;
++  bool paused = false;
++  bool _remove = false;
++  bool _blur = true;
++  bool _colorCorrection = false;
++  bool _smartZoom = false;
+   bool _enableAudio = true;
+   LocalAudioTrack? _audioTrack;
+   LocalVideoTrack? _videoTrack;
+@@ -109,6 +114,61 @@ class _PreJoinPageState extends State<PreJoinPage> {
+     setState(() {});
+   }
+ 
++  Future<void> _pauseVideoTrack(value) async {
++    paused = value;
++    if (paused) {
++      await _videoTrack?.disable();
++    } else {
++      await _videoTrack?.enable();
++    }
++    setState(() {});
++  }
++
++  Future<void> _setReplaceModeSdk(value) async {
++    _remove = value;
++    if (_remove) {
++      _blur = false;
++      _videoTrack!.setPipelineMode(PipelineMode.remove);
++    } else {
++      _videoTrack!.setPipelineMode(PipelineMode.noEffects);
++    }
++    setState(() {});
++  }
++
++  Future<void> _setBlurModeSdk(value) async {
++    _blur = value;
++    if (_blur) {
++      _remove = false;
++      _videoTrack!.setPipelineMode(PipelineMode.blur);
++      _videoTrack!.setBlurPower(0.7);
++    } else {
++      _videoTrack!.setPipelineMode(PipelineMode.noEffects);
++    }
++    setState(() {});
++  }
++
++  Future<void> _setColorCorrectionSdk(value) async {
++    _colorCorrection = value;
++    if (_colorCorrection){
++      _videoTrack!.setColorCorrectionMode(ColorCorrectionMode.colorCorrectionMode);
++      _videoTrack!.setColorFilterStrength(0.5);
++    } else {
++      _videoTrack!.setColorCorrectionMode(ColorCorrectionMode.noFilterMode);
++      _videoTrack!.setColorFilterStrength(0.0);
++    }
++    setState(() {});
++  }
++
++  Future<void> _setSmartZoomSdk(value) async {
++    _smartZoom = value;
++    if (_smartZoom) {
++      _videoTrack!.setZoomLevel(0.5);
++    } else {
++      _videoTrack!.setZoomLevel(0);
++    }
++    setState(() {});
++  }
++
+   Future<void> _setEnableAudio(value) async {
+     _enableAudio = value;
+     if (!_enableAudio) {
+@@ -143,12 +203,31 @@ class _PreJoinPageState extends State<PreJoinPage> {
+     }
+ 
+     if (_selectedVideoDevice != null) {
+-      _videoTrack =
+-          await LocalVideoTrack.createCameraTrack(CameraCaptureOptions(
++      _videoTrack = await LocalVideoTrack.createCameraTrack(CameraCaptureOptions(
+         deviceId: _selectedVideoDevice!.deviceId,
+         params: _selectedVideoParameters,
++        // set effects SDK parameter to true
++        effectsSdkRequired: true,
+       ));
+       await _videoTrack!.start();
++      // initialize Effects SDK
++      AuthStatus status = await _videoTrack!.auth('YOUR_CUSTOMER_KEY');
++      switch (status){
++        case AuthStatus.active:
++          //Set pipeline options
++          _videoTrack!.setPipelineMode(PipelineMode.blur);
++          _videoTrack!.setBlurPower(0.75);
++          break;
++        case AuthStatus.expired:
++          // TODO: Handle this case as you need.
++          break;
++        case AuthStatus.inactive:
++          // TODO: Handle this case as you need.
++          break;
++        case AuthStatus.unavailable:
++          // TODO: Handle this case as you need.
++          break;
++      }
+     }
+   }
+ 
+@@ -318,6 +397,71 @@ class _PreJoinPageState extends State<PreJoinPage> {
+                         ],
+                       ),
+                     ),
++                    Padding(
++                      padding: const EdgeInsets.only(bottom: 5),
++                      child: Row(
++                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
++                        children: [
++                          const Text('Pause video:'),
++                          Switch(
++                            value: paused,
++                            onChanged: (value) => _pauseVideoTrack(value),
++                          ),
++                        ],
++                      ),
++                    ),
++                    Padding(
++                      padding: const EdgeInsets.only(bottom: 5),
++                      child: Row(
++                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
++                        children: [
++                          const Text('Remove:'),
++                          Switch(
++                            value: _remove,
++                            onChanged: (value) => _setReplaceModeSdk(value),
++                          ),
++                        ],
++                      ),
++                    ),
++                    Padding(
++                      padding: const EdgeInsets.only(bottom: 5),
++                      child: Row(
++                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
++                        children: [
++                          const Text('Blur:'),
++                          Switch(
++                            value: _blur,
++                            onChanged: (value) => _setBlurModeSdk(value),
++                          ),
++                        ],
++                      ),
++                    ),
++                    Padding(
++                      padding: const EdgeInsets.only(bottom: 5),
++                      child: Row(
++                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
++                        children: [
++                          const Text('SmartZoom:'),
++                          Switch(
++                            value: _smartZoom,
++                            onChanged: (value) => _setSmartZoomSdk(value),
++                          ),
++                        ],
++                      ),
++                    ),
++                    Padding(
++                      padding: const EdgeInsets.only(bottom: 5),
++                      child: Row(
++                        mainAxisAlignment: MainAxisAlignment.spaceBetween,
++                        children: [
++                          const Text('ColorCorrection:'),
++                          Switch(
++                            value: _colorCorrection,
++                            onChanged: (value) => _setColorCorrectionSdk(value),
++                          ),
++                        ],
++                      ),
++                    ),
+                     Padding(
+                       padding: const EdgeInsets.only(bottom: 25),
+                       child: DropdownButtonHideUnderline(
+diff --git a/integration_doc.md b/integration_doc.md
+new file mode 100644
+index 0000000..606642f
+--- /dev/null
++++ b/integration_doc.md
+@@ -0,0 +1,58 @@
++# Effects SDK flutter LiveKit integration
++
++## Instructions
++
++1. Clone flitter WebRTC and flutter LiveKit repositories
++2. Download and apply patch from this repository
++3. Download effects SDK release for your platform
++4. Add Effects SDK as webRTC dependency
++
++## How to use
++
++1. Create cameraVideoTrack by using LocalVideoTrack.createCameraTrack() with effectsEdkRequired flag
++2. Call auth() method with your customer key
++3. Set Effects SDK parameters for you video track
++
++```dart
++_videoTrack = await LocalVideoTrack.createCameraTrack(
++  CameraCaptureOptions(
++      deviceId: _selectedVideoDevice!.deviceId,
++      params: _selectedVideoParameters,
++      effectsSdkRequired: true,
++  )
++);
++await _videoTrack!.start();
++AuthStatus status = await _videoTrack!.auth('YOUR_CUSTOMER_KEY');
++switch (status){
++    case AuthStatus.active:
++      _videoTrack!.setPipelineMode(PipelineMode.blur);
++      _videoTrack!.setBlurPower(0.99);
++      break;
++    case AuthStatus.expired:
++      // TODO: Handle this case.
++      break;
++    case AuthStatus.inactive:
++      // TODO: Handle this case.
++      break;
++    case AuthStatus.unavailable:
++      // TODO: Handle this case.
++      break;
++}
++
++```
++
++You can manage all sdk parameters without VideoTrack recreation.
++
++## EffectsSDK methods
++
++
++
++## Technical details
++
++We create custom CameraVideoCapturer instance for Effects SDK camera pipeline instance.
++You can change it to LiteCameraPipeline if you need.
++
++## Additional links
++
++1. Platform documentation (iOS, android)
++2. Effects SDK site
+diff --git a/lib/src/track/local/video.dart b/lib/src/track/local/video.dart
+index 44d3afc..b20d7ab 100644
+--- a/lib/src/track/local/video.dart
++++ b/lib/src/track/local/video.dart
+@@ -254,6 +254,80 @@ class LocalVideoTrack extends LocalTrack with VideoTrack {
+ // Convenience extensions
+ //
+ extension LocalVideoTrackExt on LocalVideoTrack {
++  /**
++      Effects SDK get\set extension. Use it to control effects SDK options
++   */
++  Future<rtc.AuthStatus> auth(String customerId, {String? apiUrl}) async {
++    return rtc.Helper.auth(mediaStreamTrack, customerId, apiUrl);
++  }
++
++  Future<rtc.AuthStatus> localAuth(String localKey) async {
++    return rtc.Helper.localAuth(mediaStreamTrack, localKey);;
++  }
++
++  Future<rtc.PipelineMode> getPipelineMode() async {
++    return rtc.Helper.getEffectsSdkPipelineMode(mediaStreamTrack);
++  }
++
++  void setPipelineMode(rtc.PipelineMode mode) {
++    rtc.Helper.setEffectsSdkPipelineMode(mediaStreamTrack, mode);
++  }
++
++  void setBlurPower(double blurPower) {
++    rtc.Helper.setEffectsSdkBlurPower(mediaStreamTrack, blurPower);
++  }
++
++  void setBackgroundImage(Uint8List data) {
++    rtc.Helper.setEffectsSdkBackgroundImage(mediaStreamTrack, data);
++  }
++
++  void enableBeautification(bool enable) {
++    rtc.Helper.enableEffectsSdkBeautification(mediaStreamTrack, enable);
++  }
++
++  Future<bool> isBeautificationEnabled() async {
++    return rtc.Helper.isEffectsSdkBeautificationEnabled(mediaStreamTrack);
++  }
++
++  void setBeautificationPower(double power) {
++    rtc.Helper.setEffectsSdkBeautificationPower(mediaStreamTrack, power);
++  }
++
++  Future<double> getZoomLevel() async {
++    return rtc.Helper.getEffectsSdkZoomLevel(mediaStreamTrack);
++  }
++
++  void setZoomLevel(double zoomLevel) {
++    rtc.Helper.setEffectsSdkZoomLevel(mediaStreamTrack, zoomLevel);
++  }
++
++  void enableSharpening(bool enable) {
++    rtc.Helper.enableEffectsSdkSharpening(mediaStreamTrack, enable);
++  }
++
++  Future<double> getSharpeningStrength() async {
++    return rtc.Helper.getEffectsSdkSharpeningStrength(mediaStreamTrack);
++  }
++
++  void setSharpeningStrength(double strength) {
++    rtc.Helper.setEffectsSdkSharpeningStrength(mediaStreamTrack, strength);
++  }
++
++  void setColorCorrectionMode(rtc.ColorCorrectionMode colorCorrectionMode) {
++    rtc.Helper.setEffectsSdkColorCorrectionMode(
++        mediaStreamTrack,
++        colorCorrectionMode
++    );
++  }
++
++  void setColorFilterStrength(double strength) {
++    rtc.Helper.setEffectsSdkColorFilterStrength(mediaStreamTrack, strength);
++  }
++
++  void setColorGradingReferenceImage(Uint8List data) {
++    rtc.Helper.setEffectsSdkColorGradingReferenceImage(mediaStreamTrack, data);
++  }
++
+   // Calls restartTrack under the hood
+   Future<void> setCameraPosition(CameraPosition position) async {
+     final options = currentOptions;
+diff --git a/lib/src/track/options.dart b/lib/src/track/options.dart
+index b7e63ff..ec82419 100644
+--- a/lib/src/track/options.dart
++++ b/lib/src/track/options.dart
+@@ -63,11 +63,13 @@ class CameraCaptureOptions extends VideoCaptureOptions {
+     String? deviceId,
+     double? maxFrameRate,
+     VideoParameters params = VideoParametersPresets.h720_169,
++    bool? effectsSdkRequired,
+     this.stopCameraCaptureOnMute = true,
+     TrackProcessor<VideoProcessorOptions>? processor,
+   }) : super(
+           params: params,
+           deviceId: deviceId,
++          effectsSdkRequired: effectsSdkRequired,
+           maxFrameRate: maxFrameRate,
+           processor: processor,
+         );
+@@ -80,6 +82,7 @@ class CameraCaptureOptions extends VideoCaptureOptions {
+         super(
+           params: captureOptions.params,
+           deviceId: captureOptions.deviceId,
++          effectsSdkRequired: captureOptions.effectsSdkRequired,
+           maxFrameRate: captureOptions.maxFrameRate,
+         );
+ 
+@@ -91,6 +94,7 @@ class CameraCaptureOptions extends VideoCaptureOptions {
+         'facingMode':
+             cameraPosition == CameraPosition.front ? 'user' : 'environment'
+     };
++    constraints['effectsSdkRequired'] = effectsSdkRequired;
+     if (deviceId != null && deviceId!.isNotEmpty) {
+       if (kIsWeb) {
+         if (isChrome129OrLater()) {
+@@ -223,6 +227,7 @@ abstract class VideoCaptureOptions extends LocalTrackOptions {
+   /// List<DesktopCapturerSource> desktopSources = await rtc.desktopCapturer.getSources(types: [rtc.SourceType.Screen, rtc.SourceType.Window]);
+   /// </pre>
+   final String? deviceId;
++  final bool? effectsSdkRequired;
+ 
+   // Limit the maximum frameRate of the capture device.
+   final double? maxFrameRate;
+@@ -233,6 +238,7 @@ abstract class VideoCaptureOptions extends LocalTrackOptions {
+   const VideoCaptureOptions({
+     this.params = VideoParametersPresets.h540_169,
+     this.deviceId,
++    this.effectsSdkRequired,
+     this.maxFrameRate,
+     this.processor,
+   });
+diff --git a/pubspec.lock b/pubspec.lock
+index b39f0ae..2cd7406 100644
+--- a/pubspec.lock
++++ b/pubspec.lock
+@@ -141,10 +141,10 @@ packages:
+     dependency: "direct main"
+     description:
+       name: dart_webrtc
+-      sha256: "8565f1f1f412b8a6fd862f3a157560811e61eeeac26741c735a5d2ff409a0202"
++      sha256: "5b76fd85ac95d6f5dee3e7d7de8d4b51bfbec1dc73804647c6aebb52d6297116"
+       url: "https://pub.dev"
+     source: hosted
+-    version: "1.5.3"
++    version: "1.5.3+hotfix.2"
+   dbus:
+     dependency: transitive
+     description:
+@@ -219,11 +219,10 @@ packages:
+   flutter_webrtc:
+     dependency: "direct main"
+     description:
+-      name: flutter_webrtc
+-      sha256: "4f0d6e248f178e617f249b6a2f432b5981e3300c2896fc8d476fc2aa1f525547"
+-      url: "https://pub.dev"
+-    source: hosted
+-    version: "0.13.1"
++      path: "../flutter-webrtc-patch"
++      relative: false
++    source: path
++    version: "0.14.0"
+   glob:
+     dependency: transitive
+     description:
+@@ -328,6 +327,14 @@ packages:
+       url: "https://pub.dev"
+     source: hosted
+     version: "1.16.0"
++  mime_type:
++    dependency: "direct main"
++    description:
++      name: mime_type
++      sha256: d652b613e84dac1af28030a9fba82c0999be05b98163f9e18a0849c6e63838bb
++      url: "https://pub.dev"
++    source: hosted
++    version: "1.0.1"
+   mockito:
+     dependency: "direct dev"
+     description:
+@@ -353,7 +360,7 @@ packages:
+     source: hosted
+     version: "2.2.0"
+   path:
+-    dependency: transitive
++    dependency: "direct main"
+     description:
+       name: path
+       sha256: "75cca69d1490965be98c73ceaea117e8a04dd21217b37b292c9ddbec0d955bc5"
+@@ -593,10 +600,10 @@ packages:
+     dependency: transitive
+     description:
+       name: webrtc_interface
+-      sha256: e92afec11152a9ccb5c9f35482754edd99696e886ab6acaf90c06dd2d09f09eb
++      sha256: "86fe3afc81a08481dfb25cf14a5a94e27062ecef25544783f352c914e0bbc1ca"
+       url: "https://pub.dev"
+     source: hosted
+-    version: "1.2.2+hotfix.1"
++    version: "1.2.2+hotfix.2"
+   win32:
+     dependency: transitive
+     description:
+diff --git a/pubspec.yaml b/pubspec.yaml
+index 1f1a41e..d08a9ef 100644
+--- a/pubspec.yaml
++++ b/pubspec.yaml
+@@ -37,7 +37,8 @@ dependencies:
+   uuid: ^4.5.1
+   synchronized: ^3.0.0+3
+   protobuf: ^3.0.0
+-  flutter_webrtc: ^0.14.0
++  flutter_webrtc:
++    path: ../flutter-webrtc-patch
+   device_info_plus: ^11.3.0
+   dart_webrtc: ^1.5.3
+   sdp_transform: ^0.3.2
diff --git a/github_patch_repository/readme.md b/github_patch_repository/readme.md
new file mode 100644
index 0000000..61de9bc
--- /dev/null
+++ b/github_patch_repository/readme.md
@@ -0,0 +1,70 @@
+# Effects SDK flutter LiveKit integration
+
+Tested for **LiveKit v2.4.6** and **webRTC v0.14.0**
+
+## Instructions
+
+1. Clone flutter [WebRTC](https://github.com/flutter-webrtc/flutter-webrtc) and [LiveKit](https://github.com/livekit/client-sdk-flutter) repositories
+2. Download patch([WebRTC](webRTC-patch.diff) and [livekit](livekit-patch.diff)) from this repository and apply it
+3. Download effects SDK release for your platform
+4. Add Effects SDK as webRTC dependency (to **webRTC_repo_root/android/libs** catalog)
+5. Add LiveKit repo as dependency to your project
+
+## LiveKit demo app
+
+We made some changes in **livekit_repo_root/example** app, so you can build it as is from patched repository
+
+## How to use
+
+1. Create cameraVideoTrack by using LocalVideoTrack.createCameraTrack() with effectsEdkRequired flag
+2. Call auth() method with your customer key
+3. Set Effects SDK parameters for you video track
+
+```dart
+_videoTrack = await LocalVideoTrack.createCameraTrack(
+  CameraCaptureOptions(
+      deviceId: _selectedVideoDevice!.deviceId,
+      params: _selectedVideoParameters,
+      effectsSdkRequired: true,
+  )
+);
+await _videoTrack!.start();
+AuthStatus status = await _videoTrack!.auth('YOUR_CUSTOMER_KEY');
+switch (status){
+    case AuthStatus.active:
+      _videoTrack!.setPipelineMode(PipelineMode.blur);
+      _videoTrack!.setBlurPower(0.99);
+      break;
+    case AuthStatus.expired:
+      // TODO: Handle this case.
+      break;
+    case AuthStatus.inactive:
+      // TODO: Handle this case.
+      break;
+    case AuthStatus.unavailable:
+      // TODO: Handle this case.
+      break;
+}
+
+```
+
+You can manage all sdk parameters without VideoTrack recreation.
+
+## EffectsSDK methods
+
+Check platform specifications:
+1. [iOS]
+2. [android](https://github.com/EffectsSDK/android-integration-sample)
+
+
+## Technical details
+
+All additional LocalVideoTrack methods was implemented as extension functions. Also,
+we create custom CameraVideoCapturer instance for Effects SDK camera pipeline(android).
+You can modify our solution as you need or try another way for integrations (for example with custom VideoProcessor).
+Also you can replace CameraPipeline to lite version of it, if need.
+
+## Additional links
+
+1. Platform documentation (iOS, [android](https://github.com/EffectsSDK/android-integration-sample))
+2. Effects SDK [site](https://effectssdk.ai/)
diff --git a/github_patch_repository/webRTC-patch.diff b/github_patch_repository/webRTC-patch.diff
new file mode 100644
index 0000000..9496f70
--- /dev/null
+++ b/github_patch_repository/webRTC-patch.diff
@@ -0,0 +1,1114 @@
+diff --git a/.gitignore b/.gitignore
+index 0bab26c..6b6674e 100644
+--- a/.gitignore
++++ b/.gitignore
+@@ -11,6 +11,8 @@ example/.flutter-plugins
+ example/android/local.properties
+ .dart_tool/package_config.json
+ android/.project
++android/libs/*
++!android/libs/readme.txt
+ example/ios/Runner/GeneratedPluginRegistrant.m
+ example/ios/Runner/GeneratedPluginRegistrant.h
+ example/ios/Flutter/Generated.xcconfig
+diff --git a/android/build.gradle b/android/build.gradle
+index f9b288f..e3a4287 100644
+--- a/android/build.gradle
++++ b/android/build.gradle
+@@ -53,6 +53,7 @@ android {
+ 
+ dependencies {
+     implementation 'io.github.webrtc-sdk:android:125.6422.03'
++    implementation(files("libs/Effects_SDK_v.2.11.4.aar"))
+     implementation 'com.github.davidliu:audioswitch:89582c47c9a04c62f90aa5e57251af4800a62c9a'
+     implementation 'androidx.annotation:annotation:1.1.0'
+     implementation "org.jetbrains.kotlin:kotlin-stdlib-jdk7:$kotlin_version"
+diff --git a/android/libs/readme.txt b/android/libs/readme.txt
+new file mode 100644
+index 0000000..ca50f49
+--- /dev/null
++++ b/android/libs/readme.txt
+@@ -0,0 +1 @@
++Place Effects SDK lib here
+diff --git a/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java b/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java
+index 0b0998f..44d9b34 100755
+--- a/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java
++++ b/android/src/main/java/com/cloudwebrtc/webrtc/GetUserMediaImpl.java
+@@ -9,6 +9,7 @@ import android.content.ContentValues;
+ import android.content.Context;
+ import android.content.Intent;
+ import android.content.pm.PackageManager;
++import android.graphics.Bitmap;
+ import android.graphics.Point;
+ import android.hardware.camera2.CameraManager;
+ import android.media.AudioDeviceInfo;
+@@ -49,6 +50,8 @@ import com.cloudwebrtc.webrtc.utils.ObjectType;
+ import com.cloudwebrtc.webrtc.utils.PermissionUtils;
+ import com.cloudwebrtc.webrtc.video.LocalVideoTrack;
+ import com.cloudwebrtc.webrtc.video.VideoCapturerInfo;
++import com.cloudwebrtc.webrtc.video.camera.EffectsSDKVideoCapturer;
++import com.effectssdk.tsvb.EffectsSDKStatus;
+ 
+ import org.webrtc.AudioSource;
+ import org.webrtc.AudioTrack;
+@@ -163,6 +166,144 @@ public class GetUserMediaImpl {
+                 });
+     }
+ 
++    public void setEffectsSdkBlurPower(String trackId, double blurPower) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setBlurPower((float) blurPower);
++        }
++    }
++
++    public EffectsSDKStatus initializeEffectsSdk(String trackId, String customerId, String url) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            return capturer.initializeEffectsSdk(customerId, url);
++        }
++        return EffectsSDKStatus.INACTIVE;
++    }
++
++    public void enableEffectsSdkVideoStream(String trackId, boolean enabled) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.enableVideo(enabled);
++        }
++    }
++
++    public EffectsSDKStatus initializeEffectsSdkLocal(String trackId, String localKey) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            return capturer.initializeEffectsSdkLocal(localKey);
++        }
++        return EffectsSDKStatus.INACTIVE;
++    }
++
++    public void setEffectsSdkPipelineMode(String trackId, String pipelineMode) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setPipelineMode(pipelineMode);
++        }
++    }
++
++    public void enableEffectsSdkBeautification(String trackId, boolean enableBeautification) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.enableBeautification(enableBeautification);
++        }
++    }
++
++    public boolean isEffectsSdkBeautificationEnabled(String trackId) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            return capturer.isBeautificationEnabled();
++        }
++        return false;
++    }
++
++    public void setEffectsSdkBeautificationPower(String trackId, double beautificationPower) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setBeautificationPower(beautificationPower);
++        }
++    }
++
++    public double getEffectsSdkZoomLevel(String trackId) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            return capturer.getZoomLevel();
++        }
++        return 0;
++    }
++
++    public void setEffectsSdkZoomLevel(String trackId, double zoomLevel) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setZoomLevel(zoomLevel);
++        }
++    }
++
++    public void enableEffectsSdkSharpening(String trackId, boolean enableSharpening) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.enableSharpening(enableSharpening);
++        }
++    }
++
++    public double getEffectsSdkSharpeningStrength(String trackId) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            return capturer.getSharpeningStrength();
++        }
++        return 0;
++    }
++
++    public void setEffectsSdkSharpeningStrength(String trackId, double strength) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setSharpeningStrength(strength);
++        }
++    }
++
++    public void setEffectsSdkColorFilterStrength(String trackId, double strength) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setColorFilterStrength(strength);
++        }
++    }
++
++    public void setEffectsSdkBitmapImage(String trackId, Bitmap bitmap) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setBackgroundBitmap(bitmap);
++        }
++    }
++
++    public void setEffectsSdkColorGradingReferenceImage(String trackId, Bitmap bitmap) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setColorGradingReference(bitmap);
++        }
++    }
++
++    public void setEffectsSdkColorCorrectionMode(String trackId, String colorCorrectionMode) {
++        EffectsSDKVideoCapturer capturer = getEffectsSdkVideoCapturer(trackId);
++        if (capturer != null) {
++            capturer.setColorCorrectionMode(colorCorrectionMode);
++        }
++    }
++
++    private EffectsSDKVideoCapturer getEffectsSdkVideoCapturer(String trackId) {
++        try {
++            VideoCapturerInfoEx info = mVideoCapturers.get(trackId);
++            if (info != null) {
++                return (EffectsSDKVideoCapturer) info.capturer;
++            }
++        } catch (ClassCastException e) {
++            Log.w(TAG, "Can't get EffectsSDKVideoCapturer instance. Make sure effectsSdkRequired is true.");
++        }
++        return null;
++    }
++
++
++
+     public static class ScreenRequestPermissionsFragment extends Fragment {
+ 
+         private ResultReceiver resultReceiver = null;
+@@ -271,14 +412,24 @@ public class GetUserMediaImpl {
+      * if not matched camera with specified facing mode.
+      */
+     private Pair<String, VideoCapturer> createVideoCapturer(
+-            CameraEnumerator enumerator, boolean isFacing, String sourceId, CameraEventsHandler cameraEventsHandler) {
++            CameraEnumerator enumerator,
++            boolean isFacing,
++            String sourceId,
++            CameraEventsHandler cameraEventsHandler,
++            boolean effectsSdkRequired
++    ) {
+         VideoCapturer videoCapturer;
+         // if sourceId given, use specified sourceId first
+         final String[] deviceNames = enumerator.getDeviceNames();
+         if (sourceId != null && !sourceId.equals("")) {
+             for (String name : deviceNames) {
+                 if (name.equals(sourceId)) {
+-                    videoCapturer = enumerator.createCapturer(name, cameraEventsHandler);
++                    if (!effectsSdkRequired)
++                        videoCapturer = enumerator.createCapturer(name, cameraEventsHandler);
++                    else {
++                        // Create EffectsSDK capturer here
++                        videoCapturer = new EffectsSDKVideoCapturer(name, cameraEventsHandler, enumerator);
++                    }
+                     if (videoCapturer != null) {
+                         Log.d(TAG, "create user specified camera " + name + " succeeded");
+                         return new Pair<>(name, videoCapturer);
+@@ -355,6 +506,17 @@ public class GetUserMediaImpl {
+         return null;
+     }
+ 
++    private boolean getEffectsSDKConstraint(ConstraintsMap mediaConstraints) {
++        try {
++            if (mediaConstraints != null && mediaConstraints.hasKey("effectsSdkRequired")) {
++                return mediaConstraints.getBoolean("effectsSdkRequired");
++            }
++        } catch (NullPointerException e) {
++            return false;
++        }
++        return false;
++    }
++
+     private ConstraintsMap getUserAudio(ConstraintsMap constraints, MediaStream stream) {
+         AudioSwitchManager.instance.start();
+         MediaConstraints audioConstraints = new MediaConstraints();
+@@ -723,8 +885,15 @@ public class GetUserMediaImpl {
+         String facingMode = getFacingMode(videoConstraintsMap);
+         isFacing = facingMode == null || !facingMode.equals("environment");
+         String deviceId = getSourceIdConstraint(videoConstraintsMap);
++        boolean effectsSdkRequired = getEffectsSDKConstraint(videoConstraintsMap);
+         CameraEventsHandler cameraEventsHandler = new CameraEventsHandler();
+-        Pair<String, VideoCapturer> result = createVideoCapturer(cameraEnumerator, isFacing, deviceId, cameraEventsHandler);
++        Pair<String, VideoCapturer> result = createVideoCapturer(
++                cameraEnumerator,
++                isFacing,
++                deviceId,
++                cameraEventsHandler,
++                effectsSdkRequired
++        );
+ 
+         if (result == null) {
+             return null;
+diff --git a/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java b/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java
+index 8444c0e..9e4609c 100644
+--- a/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java
++++ b/android/src/main/java/com/cloudwebrtc/webrtc/MethodCallHandlerImpl.java
+@@ -5,7 +5,8 @@ import static com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils.parseMediaConst
+ import android.app.Activity;
+ import android.content.Context;
+ import android.content.pm.PackageManager;
+-import android.graphics.SurfaceTexture;
++import android.graphics.Bitmap;
++import android.graphics.BitmapFactory;
+ import android.hardware.Camera;
+ import android.hardware.Camera.CameraInfo;
+ import android.media.MediaRecorder;
+@@ -14,7 +15,6 @@ import android.media.AudioDeviceInfo;
+ import android.os.Build;
+ import android.util.Log;
+ import android.util.LongSparseArray;
+-import android.view.Surface;
+ 
+ import androidx.annotation.NonNull;
+ import androidx.annotation.Nullable;
+@@ -37,10 +37,10 @@ import com.cloudwebrtc.webrtc.utils.EglUtils;
+ import com.cloudwebrtc.webrtc.utils.ObjectType;
+ import com.cloudwebrtc.webrtc.utils.PermissionUtils;
+ import com.cloudwebrtc.webrtc.utils.Utils;
+-import com.cloudwebrtc.webrtc.video.VideoCapturerInfo;
+ import com.cloudwebrtc.webrtc.video.camera.CameraUtils;
+ import com.cloudwebrtc.webrtc.video.camera.Point;
+ import com.cloudwebrtc.webrtc.video.LocalVideoTrack;
++import com.effectssdk.tsvb.EffectsSDKStatus;
+ import com.twilio.audioswitch.AudioDevice;
+ 
+ import org.webrtc.AudioTrack;
+@@ -95,7 +95,6 @@ import io.flutter.plugin.common.MethodCall;
+ import io.flutter.plugin.common.MethodChannel.MethodCallHandler;
+ import io.flutter.plugin.common.MethodChannel.Result;
+ import io.flutter.view.TextureRegistry;
+-import io.flutter.view.TextureRegistry.SurfaceTextureEntry;
+ 
+ public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
+   static public final String TAG = "FlutterWebRTCPlugin";
+@@ -1015,6 +1014,128 @@ public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
+         }
+         break;
+       }
++      case "getPipelineMode": {
++        String trackId = call.argument("trackId");
++        break;
++      }
++      case "auth": {
++        String trackId = call.argument("trackId");
++        String customerKey = call.argument("customerKey");
++        String apiUrl = call.argument("apiUrl");
++        EffectsSDKStatus status = initializeEffectsSdk(trackId, customerKey, apiUrl);
++        result.success(status.toString());
++        break;
++      }
++      case "localAuth": {
++        String trackId = call.argument("trackId");
++        String localKey = call.argument("localKey");
++        result.success(initializeEffectsSdkLocal(trackId, localKey));
++        break;
++      }
++      case "setPipelineMode": {
++        String trackId = call.argument("trackId");
++        String pipelineMode = call.argument("pipelineMode");
++        setEffectsSdkPipelineMode(trackId, pipelineMode);
++        break;
++      }
++      case "setBlurPower": {
++        String trackId = call.argument("trackId");
++        double blurPower = call.argument("blurPower");
++        setEffectsSdkBlurPower(trackId, blurPower);
++        result.success(null);
++        break;
++      }
++      case "setBackgroundImage": {
++        String trackId = call.argument("trackId");
++        try {
++          byte[] bitmapBytes = call.argument("image");
++          Bitmap bitmap = BitmapFactory.decodeByteArray(bitmapBytes, 0, bitmapBytes.length);
++          if (bitmap != null) {
++              setEffectsSdkBackgroundImage(trackId, bitmap);
++          } else {
++              Log.e(TAG, "Decode bitmap error");
++          }
++        } catch (NullPointerException e){
++          Log.e(TAG, "Image bytes was corrupted");
++        }
++        break;
++      }
++      case "enableBeautification": {
++        String trackId = call.argument("trackId");
++        boolean enableBeautification = call.argument("enable");
++        enableEffectsSdkBeautification(trackId, enableBeautification);
++        break;
++      }
++      case "isBeautificationEnabled": {
++        String trackId = call.argument("trackId");
++        boolean isEnabled = isEffectsSdkBeautificationEnabled(trackId);
++        result.success(isEnabled);
++        break;
++      }
++      case "setBeautificationPower": {
++        String trackId = call.argument("trackId");
++        double beautificationPower = call.argument("beautificationPower");
++        setEffectsSdkBeautificationPower(trackId, beautificationPower);
++        break;
++      }
++      case "getZoomLevel": {
++        String trackId = call.argument("trackId");
++        double zoomLevel = getEffectsSdkZoomLevel(trackId);
++        result.success(zoomLevel);
++        break;
++      }
++      case "setZoomLevel": {
++        String trackId = call.argument("trackId");
++        double zoomLevel = call.argument("zoomLevel");
++        setEffectsSdkZoomLevel(trackId, zoomLevel);
++        break;
++      }
++      case "enableSharpening": {
++        String trackId = call.argument("trackId");
++        boolean enableSharpening = call.argument("enable");
++        enableEffectsSdkSharpening(trackId, enableSharpening);
++        break;
++      }
++      case "getSharpeningStrength": {
++        String trackId = call.argument("trackId");
++        double sharpeningStrength = getEffectsSdkSharpeningStrength(trackId);
++        result.success(sharpeningStrength);
++        break;
++      }
++      case "setSharpeningStrength": {
++        String trackId = call.argument("trackId");
++        double strength = call.argument("strength");
++        setEffectsSdkSharpeningStrength(trackId, strength);
++        break;
++      }
++      case "setColorCorrectionMode": {
++        String trackId = call.argument("trackId");
++        String colorCorrectionMode = call.argument("colorCorrectionMode");
++        setEffectsSdkColorCorrectionMode(trackId, colorCorrectionMode);
++        break;
++      }
++      case "setColorFilterStrength": {
++        String trackId = call.argument("trackId");
++        double strength = call.argument("strength");
++        setEffectsSdkColorFilterStrength(trackId, strength);
++        break;
++      }
++      case "setColorGradingReferenceImage": {
++        String trackId = call.argument("trackId");
++        try {
++          byte[] referenceBytes = call.argument("reference");
++          Bitmap bitmap = BitmapFactory.decodeByteArray(referenceBytes, 0, referenceBytes.length);
++          if (bitmap != null) {
++            setEffectsSdkColorGradingReferenceImage(trackId, bitmap);
++          } else {
++            Log.e(TAG, "Decode bitmap error");
++          }
++        } catch (NullPointerException e){
++          Log.e(TAG, "Image bytes was corrupted");
++        }
++        break;
++      }
++
+       default:
+         if(frameCryptor.handleMethodCall(call, result)) {
+           break;
+@@ -1608,6 +1729,7 @@ public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
+ 
+   public void mediaStreamTrackSetEnabled(final String id, final boolean enabled, String peerConnectionId) {
+     MediaStreamTrack track = getTrackForId(id, peerConnectionId);
++    getUserMediaImpl.enableEffectsSdkVideoStream(id, enabled);
+ 
+     if (track == null) {
+       Log.d(TAG, "mediaStreamTrackSetEnabled() track is null");
+@@ -2290,4 +2412,70 @@ public class MethodCallHandlerImpl implements MethodCallHandler, StateProvider {
+             activity,
+             permissions.toArray(new String[permissions.size()]), callback);
+   }
++
++
++  void setEffectsSdkBlurPower(String trackId, double blurPower) {
++    getUserMediaImpl.setEffectsSdkBlurPower(trackId, blurPower);
++  }
++
++  EffectsSDKStatus initializeEffectsSdk(String trackId, String customerKey, String apiUrl) {
++    return getUserMediaImpl.initializeEffectsSdk(trackId, customerKey, apiUrl);
++  }
++
++  EffectsSDKStatus initializeEffectsSdkLocal(String trackId, String localKey) {
++    return getUserMediaImpl.initializeEffectsSdkLocal(trackId, localKey);
++  }
++
++  private void setEffectsSdkPipelineMode(String trackId, String pipelineMode) {
++    getUserMediaImpl.setEffectsSdkPipelineMode(trackId, pipelineMode);
++  }
++
++  private void setEffectsSdkBackgroundImage(String trackId, Bitmap bitmap) {
++    getUserMediaImpl.setEffectsSdkBitmapImage(trackId, bitmap);
++  }
++
++  private void enableEffectsSdkBeautification(String trackId, boolean enableBeautification) {
++    getUserMediaImpl.enableEffectsSdkBeautification(trackId, enableBeautification);
++  }
++
++  private boolean isEffectsSdkBeautificationEnabled(String trackId) {
++    return getUserMediaImpl.isEffectsSdkBeautificationEnabled(trackId);
++  }
++
++  private void setEffectsSdkBeautificationPower(String trackId, double beautificationPower) {
++    getUserMediaImpl.setEffectsSdkBeautificationPower(trackId, beautificationPower);
++  }
++
++  private double getEffectsSdkZoomLevel(String trackId) {
++    return getUserMediaImpl.getEffectsSdkZoomLevel(trackId);
++  }
++
++  private void setEffectsSdkZoomLevel(String trackId, double zoomLevel) {
++    getUserMediaImpl.setEffectsSdkZoomLevel(trackId, zoomLevel);
++  }
++
++  private void enableEffectsSdkSharpening(String trackId, boolean enableSharpening) {
++    getUserMediaImpl.enableEffectsSdkSharpening(trackId, enableSharpening);
++  }
++
++  private double getEffectsSdkSharpeningStrength(String trackId) {
++    return getUserMediaImpl.getEffectsSdkSharpeningStrength(trackId);
++  }
++
++  private void setEffectsSdkSharpeningStrength(String trackId, double strength) {
++    getUserMediaImpl.setEffectsSdkSharpeningStrength(trackId, strength);
++  }
++
++  private void setEffectsSdkColorCorrectionMode(String trackId, String colorCorrectionMode) {
++    getUserMediaImpl.setEffectsSdkColorCorrectionMode(trackId, colorCorrectionMode);
++  }
++
++  private void setEffectsSdkColorFilterStrength(String trackId, double strength) {
++    getUserMediaImpl.setEffectsSdkColorFilterStrength(trackId, strength);
++  }
++
++  private void setEffectsSdkColorGradingReferenceImage(String trackId, Bitmap bitmap) {
++    getUserMediaImpl.setEffectsSdkColorGradingReferenceImage(trackId, bitmap);
++  }
++
+ }
+diff --git a/android/src/main/java/com/cloudwebrtc/webrtc/video/camera/EffectsSDKCameraCapturer.kt b/android/src/main/java/com/cloudwebrtc/webrtc/video/camera/EffectsSDKCameraCapturer.kt
+new file mode 100644
+index 0000000..d461d8f
+--- /dev/null
++++ b/android/src/main/java/com/cloudwebrtc/webrtc/video/camera/EffectsSDKCameraCapturer.kt
+@@ -0,0 +1,397 @@
++package com.cloudwebrtc.webrtc.video.camera
++
++import android.content.Context
++import android.graphics.Bitmap
++import android.util.Log
++import android.util.Size
++import com.effectssdk.tsvb.Camera
++import com.effectssdk.tsvb.EffectsSDK
++import com.effectssdk.tsvb.EffectsSDKStatus
++import com.effectssdk.tsvb.pipeline.CameraPipeline
++import com.effectssdk.tsvb.pipeline.ColorCorrectionMode
++import com.effectssdk.tsvb.pipeline.OnFrameAvailableListener
++import com.effectssdk.tsvb.pipeline.PipelineMode
++import kotlinx.coroutines.runBlocking
++import org.webrtc.CameraEnumerator
++import org.webrtc.CameraVideoCapturer
++import org.webrtc.CameraVideoCapturer.CameraEventsHandler
++import org.webrtc.CapturerObserver
++import org.webrtc.NV21Buffer
++import org.webrtc.SurfaceTextureHelper
++import org.webrtc.VideoFrame
++import java.net.URL
++import kotlin.coroutines.resume
++import kotlin.coroutines.suspendCoroutine
++
++
++/**
++ * Custom video capturer for Effects SDK
++ */
++class EffectsSDKVideoCapturer(
++    private val device: String,
++    private val eventsHandler: CameraEventsHandler,
++    enumerator: CameraEnumerator
++) : CameraVideoCapturer {
++
++    private var isPipelineCameraUsed: Boolean = false
++
++    private var context: Context? = null
++    private var capturerObserver: CapturerObserver? = null
++    //Default WebRTC capturer. Used until EffectsSDK not ready to provide frames
++    //You can remove this if you don't need non-processed frames
++    private var webRtcCameraCapturer: CameraVideoCapturer? = null
++
++    private var cameraPipeline: CameraPipeline? = null
++    private var defaultPipelineOptions = EffectsSdkOptionsCache()
++    private var currentPipelineOptions = EffectsSdkOptionsCache()
++
++    init {
++        //Custom event handler. Used until EffectsSDK not ready to provide frames
++        val cameraEventHandler = object : CameraEventsHandler {
++            override fun onCameraError(p0: String?) {
++                if (!isPipelineCameraUsed) eventsHandler.onCameraError(p0)
++            }
++
++            override fun onCameraDisconnected() {
++                if (!isPipelineCameraUsed) eventsHandler.onCameraDisconnected()
++            }
++
++            override fun onCameraFreezed(p0: String?) {
++                if (!isPipelineCameraUsed) eventsHandler.onCameraFreezed(p0)
++            }
++
++            override fun onCameraOpening(p0: String?) {
++                if (!isPipelineCameraUsed) eventsHandler.onCameraOpening(p0)
++            }
++
++            override fun onFirstFrameAvailable() {
++                if (!isPipelineCameraUsed) eventsHandler.onFirstFrameAvailable()
++            }
++
++            override fun onCameraClosed() {
++                if (!isPipelineCameraUsed) eventsHandler.onCameraClosed()
++            }
++
++        }
++        webRtcCameraCapturer = enumerator.createCapturer(device, cameraEventHandler)
++    }
++
++    override fun initialize(
++        surfaceTextureHelper: SurfaceTextureHelper?,
++        context: Context?,
++        observer: CapturerObserver?
++    ) {
++        if (!isPipelineCameraUsed) {
++            //Custom Capturer observer. Used until EffectsSDK not ready to provide frames
++            val nativeCapturerObserver = object : CapturerObserver {
++                override fun onCapturerStarted(p0: Boolean) {
++                    if (!isPipelineCameraUsed) capturerObserver?.onCapturerStarted(p0)
++                }
++
++                override fun onCapturerStopped() {
++                    if (!isPipelineCameraUsed) capturerObserver?.onCapturerStopped()
++
++                }
++
++                override fun onFrameCaptured(p0: VideoFrame?) {
++                    if (!isPipelineCameraUsed) capturerObserver?.onFrameCaptured(p0)
++                }
++            }
++            webRtcCameraCapturer?.initialize(surfaceTextureHelper, context, nativeCapturerObserver)
++        }
++        this.context = context
++        capturerObserver = observer
++    }
++
++
++    override fun startCapture(width: Int, height: Int, framerate: Int) {
++        if (!isPipelineCameraUsed) {
++            webRtcCameraCapturer?.startCapture(width, height, framerate)
++        } else {
++            createPipeline(height, width)
++            cameraPipeline?.setFlipX(true)
++            cameraPipeline?.startPipeline()
++            cameraPipeline?.setOnFrameAvailableListener(onFrameAvailableListener)
++        }
++    }
++
++    override fun stopCapture() {
++        if (!isPipelineCameraUsed) {
++            webRtcCameraCapturer?.stopCapture()
++        } else {
++            cameraPipeline?.setOnFrameAvailableListener(null)
++            cameraPipeline?.release()
++            cameraPipeline = null
++        }
++        eventsHandler.onCameraClosed()
++    }
++
++    private fun createPipeline(width: Int = 1280, height: Int = 720) {
++        val factory = EffectsSDK.createSDKFactory()
++        cameraPipeline = factory.createCameraPipeline(
++            context!!,
++            camera = if (device == "1") Camera.FRONT else Camera.BACK,
++            resolution = Size(width, height)
++        )
++    }
++
++    /*
++     * If you don't need frames, you should set "empty" options to avoid background segmentation
++     */
++    fun enableVideo(enabled: Boolean) {
++        if (enabled) {
++            setPipelineOptionsFromCache(currentPipelineOptions)
++            cameraPipeline?.setOnFrameAvailableListener(onFrameAvailableListener)
++        } else {
++            setPipelineOptionsFromCache(defaultPipelineOptions)
++            cameraPipeline?.setOnFrameAvailableListener(null)
++        }
++    }
++
++    override fun changeCaptureFormat(width: Int, height: Int, framerate: Int) {
++        if (!isPipelineCameraUsed) {
++            webRtcCameraCapturer?.changeCaptureFormat(width, height, framerate)
++        }
++    }
++
++    override fun dispose() {
++        if (!isPipelineCameraUsed) {
++            webRtcCameraCapturer?.dispose()
++        }
++    }
++
++    override fun isScreencast(): Boolean {
++        return false
++    }
++
++    override fun switchCamera(switchEventsHandler: CameraVideoCapturer.CameraSwitchHandler?) {
++        if (!isPipelineCameraUsed) {
++            webRtcCameraCapturer?.switchCamera(switchEventsHandler)
++        }
++        switchEventsHandler?.onCameraSwitchDone(true)
++    }
++
++    override fun switchCamera(
++        switchEventsHandler: CameraVideoCapturer.CameraSwitchHandler?,
++        p1: String?
++    ) {
++        if (!isPipelineCameraUsed) {
++            webRtcCameraCapturer?.switchCamera(switchEventsHandler, p1)
++        }
++        switchEventsHandler?.onCameraSwitchDone(true)
++    }
++
++    private fun getNV21(scaled: Bitmap): ByteArray {
++        val argb = IntArray(scaled.width * scaled.height)
++        scaled.getPixels(argb, 0, scaled.width, 0, 0, scaled.width, scaled.height)
++        val yuv = ByteArray(scaled.width * scaled.height * 3 / 2)
++        encodeYUV420SP(yuv, argb, scaled.width, scaled.height)
++        return yuv
++    }
++
++    private fun encodeYUV420SP(yuv420sp: ByteArray, argb: IntArray, width: Int, height: Int) {
++        val frameSize = width * height
++
++        var yIndex = 0
++        var uvIndex = frameSize
++
++        var R: Int
++        var G: Int
++        var B: Int
++        var Y: Int
++        var U: Int
++        var V: Int
++        var index = 0
++        for (j in 0 until height) {
++            for (i in 0 until width) {
++                R = (argb[index] and 0xff0000) shr 16
++                G = (argb[index] and 0xff00) shr 8
++                B = (argb[index] and 0xff) shr 0
++
++                Y = ((66 * R + 129 * G + 25 * B + 128) shr 8) + 16
++                U = ((-38 * R - 74 * G + 112 * B + 128) shr 8) + 128
++                V = ((112 * R - 94 * G - 18 * B + 128) shr 8) + 128
++
++                yuv420sp[yIndex++] = Y.toByte()
++                if (j % 2 == 0 && index % 2 == 0) {
++                    yuv420sp[uvIndex++] = V.toByte()
++                    yuv420sp[uvIndex++] = U.toByte()
++                }
++
++                index++
++            }
++        }
++    }
++
++    private val onFrameAvailableListener = OnFrameAvailableListener { bitmap, timestamp ->
++        if (!isPipelineCameraUsed) {
++            isPipelineCameraUsed = true
++            webRtcCameraCapturer?.stopCapture()
++            webRtcCameraCapturer?.dispose()
++            webRtcCameraCapturer = null
++        }
++        val videoFrame = VideoFrame(
++            NV21Buffer(
++                getNV21(bitmap),
++                bitmap.width,
++                bitmap.height,
++                { bitmap.recycle() }
++            ),
++            0,
++            timestamp * 1_000_000
++        )
++        capturerObserver?.onFrameCaptured(videoFrame)
++    }
++
++    fun initializeEffectsSdk(customerId: String, url: String?): EffectsSDKStatus {
++        var result: EffectsSDKStatus
++        runBlocking {
++            result = if (url == null) {
++                initializeCallback(context!!, customerId)
++            } else {
++                initializeCallback(context!!, customerId, URL(url))
++            }
++        }
++        if (result == EffectsSDKStatus.ACTIVE) {
++            createPipeline()
++            cameraPipeline?.setFlipX(true)
++            cameraPipeline?.startPipeline()
++            cameraPipeline?.setOnFrameAvailableListener(onFrameAvailableListener)
++        }
++        return result
++    }
++
++    private suspend fun initializeCallback(
++        context: Context,
++        customerId: String,
++        url: URL? = null
++    ): EffectsSDKStatus {
++        return suspendCoroutine { continuation ->
++            EffectsSDK.initialize(context, customerId, url) { sdkStatus ->
++                continuation.resume(sdkStatus)
++            }
++        }
++    }
++
++    fun initializeEffectsSdkLocal(localKey: String): EffectsSDKStatus {
++        return EffectsSDK.initialize(context!!, localKey)
++    }
++
++    fun setPipelineMode(pipelineMode: String) {
++        var value: String = pipelineMode.split('.')[1]
++        if (value == "noEffects") value = "no_effect"
++        val mode: PipelineMode = PipelineMode.valueOf(value.uppercase())
++        currentPipelineOptions.pipelineMode = mode
++        cameraPipeline?.setMode(mode)
++    }
++
++    fun setBlurPower(blurPower: Float) {
++        currentPipelineOptions.blurPower = blurPower
++        cameraPipeline?.setBlurPower(blurPower)
++    }
++
++    fun enableBeautification(enableBeautification: Boolean) {
++        currentPipelineOptions.isBeautificationEnabled = enableBeautification
++        cameraPipeline?.enableBeautification(enableBeautification)
++    }
++
++    fun isBeautificationEnabled(): Boolean {
++        return cameraPipeline?.isBeautificationEnabled()!!
++    }
++
++    fun setBeautificationPower(power: Double) {
++        val intValue = (power * 100).toInt()
++        currentPipelineOptions.beautificationPower = intValue
++        cameraPipeline?.setBeautificationPower(intValue)
++    }
++
++    fun getZoomLevel(): Double {
++        return (cameraPipeline?.getZoomLevel()!! / 100).toDouble()
++    }
++
++    fun setZoomLevel(zoomLevel: Double) {
++        val intValue = (zoomLevel * 100).toInt()
++        currentPipelineOptions.zoomLevel = intValue
++        cameraPipeline?.setZoomLevel(intValue)
++    }
++
++    fun enableSharpening(enableSharpening: Boolean) {
++        currentPipelineOptions.isSharpeningEnabled = enableSharpening
++        cameraPipeline?.enableSharpening(enableSharpening)
++    }
++
++    fun getSharpeningStrength(): Double {
++        return cameraPipeline?.getSharpeningStrength()!!.toDouble()
++    }
++
++    fun setSharpeningStrength(strength: Double) {
++        currentPipelineOptions.sharpeningStrength = strength.toFloat()
++        cameraPipeline?.setSharpeningStrength(strength.toFloat())
++    }
++
++    fun setColorCorrectionMode(mode: String) {
++        val value: String = mode.split('.')[1]
++        val colorCorrectionMode = when (value) {
++            "noFilterMode" -> ColorCorrectionMode.NO_FILTER_MODE
++            "colorCorrectionMode" -> ColorCorrectionMode.COLOR_CORRECTION_MODE
++            "colorGradingMode" -> ColorCorrectionMode.COLOR_GRADING_MODE
++            "presetMode" -> ColorCorrectionMode.PRESET_MODE
++            "lowLightMode" -> ColorCorrectionMode.LOW_LIGHT_MODE
++            else -> {
++                Log.w(
++                    this.javaClass.simpleName,
++                    "Incorrect color correction constant value. NO_FILTER_MODE set."
++                )
++                ColorCorrectionMode.NO_FILTER_MODE
++            }
++        }
++        currentPipelineOptions.colorCorrectionMode = colorCorrectionMode
++        cameraPipeline?.setColorCorrectionMode(colorCorrectionMode)
++    }
++
++    fun setColorFilterStrength(strength: Double) {
++        currentPipelineOptions.colorFilterStrength = strength.toFloat()
++        cameraPipeline?.setColorFilterStrength(strength.toFloat())
++    }
++
++    fun setColorGradingReference(bitmap: Bitmap) {
++        currentPipelineOptions.colorGradingReference = bitmap
++        cameraPipeline?.setColorGradingReferenceImage(bitmap)
++    }
++
++    fun setBackgroundBitmap(bitmap: Bitmap) {
++        currentPipelineOptions.backgroundBitmap = bitmap
++        cameraPipeline?.setBackground(bitmap)
++    }
++
++    private fun setPipelineOptionsFromCache(cache: EffectsSdkOptionsCache) {
++        cameraPipeline?.let { pipeline ->
++            pipeline.setMode(cache.pipelineMode)
++            pipeline.setBlurPower(cache.blurPower)
++            pipeline.setColorCorrectionMode(cache.colorCorrectionMode)
++            pipeline.enableSharpening(cache.isSharpeningEnabled)
++            pipeline.enableBeautification(cache.isBeautificationEnabled)
++            pipeline.setBeautificationPower(cache.beautificationPower)
++            pipeline.setColorFilterStrength(cache.colorFilterStrength)
++            pipeline.setSharpeningStrength(cache.sharpeningStrength)
++            pipeline.setZoomLevel(cache.zoomLevel)
++            cache.backgroundBitmap?.let { img -> pipeline.setBackground(img) }
++            cache.colorGradingReference?.let { img -> pipeline.setColorGradingReferenceImage(img) }
++        }
++    }
++
++    private data class EffectsSdkOptionsCache(
++        var pipelineMode: PipelineMode = PipelineMode.NO_EFFECT,
++        var blurPower: Float = 0f,
++        var colorCorrectionMode: ColorCorrectionMode = ColorCorrectionMode.NO_FILTER_MODE,
++        var isSharpeningEnabled: Boolean = false,
++        var isBeautificationEnabled: Boolean = false,
++        var beautificationPower: Int = 0,
++        var colorFilterStrength: Float = 0f,
++        var sharpeningStrength: Float = 0f,
++        var zoomLevel: Int = 0,
++        var backgroundBitmap: Bitmap? = null,
++        var colorGradingReference: Bitmap? = null
++    )
++
++}
+\ No newline at end of file
+diff --git a/lib/flutter_webrtc.dart b/lib/flutter_webrtc.dart
+index b7dd3a8..9d5ec73 100644
+--- a/lib/flutter_webrtc.dart
++++ b/lib/flutter_webrtc.dart
+@@ -3,6 +3,7 @@ library flutter_webrtc;
+ export 'package:webrtc_interface/webrtc_interface.dart'
+     hide MediaDevices, MediaRecorder, Navigator;
+ 
++export 'src/effects_sdk_constants.dart';
+ export 'src/helper.dart';
+ export 'src/desktop_capturer.dart';
+ export 'src/media_devices.dart';
+diff --git a/lib/src/effects_sdk_constants.dart b/lib/src/effects_sdk_constants.dart
+new file mode 100644
+index 0000000..e3aca0f
+--- /dev/null
++++ b/lib/src/effects_sdk_constants.dart
+@@ -0,0 +1,53 @@
++enum AuthStatus {
++  active,
++  expired,
++  inactive,
++  unavailable,
++}
++
++enum PipelineMode{
++  remove,
++  replace,
++  blur,
++  noEffects
++}
++
++enum ColorCorrectionMode{
++  noFilterMode,
++  colorCorrectionMode,
++  colorGradingMode,
++  presetMode,
++  lowLightMode
++  
++}
++
++AuthStatus parseJavaAuthStatus(String javaEnumValue) {
++  switch (javaEnumValue) {
++    case 'ACTIVE': return AuthStatus.active;
++    case 'INACTIVE': return AuthStatus.inactive;
++    case 'EXPIRED': return AuthStatus.expired;
++    case 'UNAVAILABLE': return AuthStatus.unavailable;
++    default: throw Exception('Unknown enum value: $javaEnumValue');
++  }
++}
++
++PipelineMode parseJavaPipelineMode(String javaEnumValue){
++  switch (javaEnumValue) {
++    case 'REMOVE': return PipelineMode.remove;
++    case 'REPLACE': return PipelineMode.replace;
++    case 'BLUR': return PipelineMode.blur;
++    case 'NO_EFFECTS': return PipelineMode.noEffects;
++    default: throw Exception('Unknown enum value: $javaEnumValue');
++  }
++}
++
++ColorCorrectionMode parseJavaColorCorrectionMode(String javaEnumValue){
++  switch (javaEnumValue) {
++    case 'NO_FILTER_MODE': return ColorCorrectionMode.noFilterMode;
++    case 'COLOR_CORRECTION_MODE': return ColorCorrectionMode.colorCorrectionMode;
++    case 'COLOR_GRADING_MODE': return ColorCorrectionMode.colorGradingMode;
++    case 'PRESET_MODE': return ColorCorrectionMode.presetMode;
++    case 'LOW_LIGHT_MODE': return ColorCorrectionMode.lowLightMode;
++    default: throw Exception('Unknown enum value: $javaEnumValue');
++  }
++}
+\ No newline at end of file
+diff --git a/lib/src/helper.dart b/lib/src/helper.dart
+index 6f1e966..7d09aed 100644
+--- a/lib/src/helper.dart
++++ b/lib/src/helper.dart
+@@ -179,4 +179,123 @@ class Helper {
+       throw Exception('requestCapturePermission only support for Android');
+     }
+   }
++
++  //todo [avp] add links
++  /// Effects SDK control methods. Check effectsSDK docs here:
++  /// iOS: *link*
++  /// android: *link*
++  static Future<PipelineMode> getEffectsSdkPipelineMode(mediaStreamTrack) async{
++    String mode =  await WebRTC.invokeMethod('getPipelineMode',
++      <String, dynamic>{'trackId': mediaStreamTrack.id},
++    );
++    return parseJavaPipelineMode(mode);
++  }
++
++  static Future<AuthStatus> auth(mediaStreamTrack, customerKey, apiUrl) async {
++    String status = await WebRTC.invokeMethod('auth',
++      <String, dynamic>{
++        'trackId': mediaStreamTrack.id,
++        'customerKey': customerKey,
++        'apiUrl': apiUrl
++      },
++    );
++    return parseJavaAuthStatus(status);
++  }
++
++  static Future<AuthStatus> localAuth(mediaStreamTrack, localKey,) async {
++    String status = await WebRTC.invokeMethod('localAuth',
++      <String, dynamic>{
++        'trackId': mediaStreamTrack.id,
++        'localKey': localKey
++      },
++    );
++    return parseJavaAuthStatus(status);
++  }
++
++  static setEffectsSdkPipelineMode(mediaStreamTrack, PipelineMode pipelineMode){
++    WebRTC.invokeMethod('setPipelineMode',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'pipelineMode': pipelineMode.toString()},
++    );
++  }
++
++  static setEffectsSdkBlurPower(mediaStreamTrack, blurPower){
++    WebRTC.invokeMethod('setBlurPower',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'blurPower': blurPower},
++    );
++  }
++
++  static setEffectsSdkBackgroundImage(mediaStreamTrack, imageData){
++    WebRTC.invokeMethod('setBackgroundImage',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'image': imageData},
++    );
++  }
++
++  static enableEffectsSdkBeautification(mediaStreamTrack, enable){
++    WebRTC.invokeMethod('enableBeautification',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'enable': enable},
++    );
++  }
++
++  static Future<bool> isEffectsSdkBeautificationEnabled(mediaStreamTrack) async {
++    return await WebRTC.invokeMethod('isBeautificationEnabled',
++      <String, dynamic>{'trackId': mediaStreamTrack.id},
++    );
++  }
++
++  static setEffectsSdkBeautificationPower(mediaStreamTrack, power){
++    WebRTC.invokeMethod('setBeautificationPower',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'beautificationPower': power},
++    );
++  }
++
++  static Future<double> getEffectsSdkZoomLevel(mediaStreamTrack) async {
++    return await WebRTC.invokeMethod('getZoomLevel',
++      <String, dynamic>{'trackId': mediaStreamTrack.id},
++    );
++  }
++
++  static setEffectsSdkZoomLevel(mediaStreamTrack, zoomLevel){
++    WebRTC.invokeMethod('setZoomLevel',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'zoomLevel': zoomLevel},
++    );
++  }
++
++  static enableEffectsSdkSharpening(mediaStreamTrack, enable){
++    WebRTC.invokeMethod('enableSharpening',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'enable': enable},
++    );
++  }
++
++  static Future<double> getEffectsSdkSharpeningStrength(mediaStreamTrack) async {
++    return await WebRTC.invokeMethod('getSharpeningStrength',
++      <String, dynamic>{'trackId': mediaStreamTrack.id},
++    );
++  }
++
++  static setEffectsSdkSharpeningStrength(mediaStreamTrack, strength){
++    WebRTC.invokeMethod('setSharpeningStrength',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'strength': strength},
++    );
++  }
++
++  static setEffectsSdkColorCorrectionMode(mediaStreamTrack, ColorCorrectionMode colorCorrectionMode) {
++    WebRTC.invokeMethod('setColorCorrectionMode',
++      <String, dynamic>{
++        'trackId': mediaStreamTrack.id,
++        'colorCorrectionMode': colorCorrectionMode.toString()
++      },
++    );
++  }
++
++  static setEffectsSdkColorFilterStrength(mediaStreamTrack, strength){
++    WebRTC.invokeMethod('setColorFilterStrength',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'strength': strength},
++    );
++  }
++
++  static setEffectsSdkColorGradingReferenceImage(mediaStreamTrack, data){
++    WebRTC.invokeMethod('setColorGradingReferenceImage',
++      <String, dynamic>{'trackId': mediaStreamTrack.id, 'reference': data},
++    );
++  }
+ }
diff --git a/lib/src/track/local/video.dart b/lib/src/track/local/video.dart
index 44d3afc..b20d7ab 100644
--- a/lib/src/track/local/video.dart
+++ b/lib/src/track/local/video.dart
@@ -254,6 +254,80 @@ class LocalVideoTrack extends LocalTrack with VideoTrack {
 // Convenience extensions
 //
 extension LocalVideoTrackExt on LocalVideoTrack {
+  /**
+      Effects SDK get\set extension. Use it to control effects SDK options
+   */
+  Future<rtc.AuthStatus> auth(String customerId, {String? apiUrl}) async {
+    return rtc.Helper.auth(mediaStreamTrack, customerId, apiUrl);
+  }
+
+  Future<rtc.AuthStatus> localAuth(String localKey) async {
+    return rtc.Helper.localAuth(mediaStreamTrack, localKey);;
+  }
+
+  Future<rtc.PipelineMode> getPipelineMode() async {
+    return rtc.Helper.getEffectsSdkPipelineMode(mediaStreamTrack);
+  }
+
+  void setPipelineMode(rtc.PipelineMode mode) {
+    rtc.Helper.setEffectsSdkPipelineMode(mediaStreamTrack, mode);
+  }
+
+  void setBlurPower(double blurPower) {
+    rtc.Helper.setEffectsSdkBlurPower(mediaStreamTrack, blurPower);
+  }
+
+  void setBackgroundImage(Uint8List data) {
+    rtc.Helper.setEffectsSdkBackgroundImage(mediaStreamTrack, data);
+  }
+
+  void enableBeautification(bool enable) {
+    rtc.Helper.enableEffectsSdkBeautification(mediaStreamTrack, enable);
+  }
+
+  Future<bool> isBeautificationEnabled() async {
+    return rtc.Helper.isEffectsSdkBeautificationEnabled(mediaStreamTrack);
+  }
+
+  void setBeautificationPower(double power) {
+    rtc.Helper.setEffectsSdkBeautificationPower(mediaStreamTrack, power);
+  }
+
+  Future<double> getZoomLevel() async {
+    return rtc.Helper.getEffectsSdkZoomLevel(mediaStreamTrack);
+  }
+
+  void setZoomLevel(double zoomLevel) {
+    rtc.Helper.setEffectsSdkZoomLevel(mediaStreamTrack, zoomLevel);
+  }
+
+  void enableSharpening(bool enable) {
+    rtc.Helper.enableEffectsSdkSharpening(mediaStreamTrack, enable);
+  }
+
+  Future<double> getSharpeningStrength() async {
+    return rtc.Helper.getEffectsSdkSharpeningStrength(mediaStreamTrack);
+  }
+
+  void setSharpeningStrength(double strength) {
+    rtc.Helper.setEffectsSdkSharpeningStrength(mediaStreamTrack, strength);
+  }
+
+  void setColorCorrectionMode(rtc.ColorCorrectionMode colorCorrectionMode) {
+    rtc.Helper.setEffectsSdkColorCorrectionMode(
+        mediaStreamTrack,
+        colorCorrectionMode
+    );
+  }
+
+  void setColorFilterStrength(double strength) {
+    rtc.Helper.setEffectsSdkColorFilterStrength(mediaStreamTrack, strength);
+  }
+
+  void setColorGradingReferenceImage(Uint8List data) {
+    rtc.Helper.setEffectsSdkColorGradingReferenceImage(mediaStreamTrack, data);
+  }
+
   // Calls restartTrack under the hood
   Future<void> setCameraPosition(CameraPosition position) async {
     final options = currentOptions;
diff --git a/lib/src/track/options.dart b/lib/src/track/options.dart
index b7e63ff..ec82419 100644
--- a/lib/src/track/options.dart
+++ b/lib/src/track/options.dart
@@ -63,11 +63,13 @@ class CameraCaptureOptions extends VideoCaptureOptions {
     String? deviceId,
     double? maxFrameRate,
     VideoParameters params = VideoParametersPresets.h720_169,
+    bool? effectsSdkRequired,
     this.stopCameraCaptureOnMute = true,
     TrackProcessor<VideoProcessorOptions>? processor,
   }) : super(
           params: params,
           deviceId: deviceId,
+          effectsSdkRequired: effectsSdkRequired,
           maxFrameRate: maxFrameRate,
           processor: processor,
         );
@@ -80,6 +82,7 @@ class CameraCaptureOptions extends VideoCaptureOptions {
         super(
           params: captureOptions.params,
           deviceId: captureOptions.deviceId,
+          effectsSdkRequired: captureOptions.effectsSdkRequired,
           maxFrameRate: captureOptions.maxFrameRate,
         );
 
@@ -91,6 +94,7 @@ class CameraCaptureOptions extends VideoCaptureOptions {
         'facingMode':
             cameraPosition == CameraPosition.front ? 'user' : 'environment'
     };
+    constraints['effectsSdkRequired'] = effectsSdkRequired;
     if (deviceId != null && deviceId!.isNotEmpty) {
       if (kIsWeb) {
         if (isChrome129OrLater()) {
@@ -223,6 +227,7 @@ abstract class VideoCaptureOptions extends LocalTrackOptions {
   /// List<DesktopCapturerSource> desktopSources = await rtc.desktopCapturer.getSources(types: [rtc.SourceType.Screen, rtc.SourceType.Window]);
   /// </pre>
   final String? deviceId;
+  final bool? effectsSdkRequired;
 
   // Limit the maximum frameRate of the capture device.
   final double? maxFrameRate;
@@ -233,6 +238,7 @@ abstract class VideoCaptureOptions extends LocalTrackOptions {
   const VideoCaptureOptions({
     this.params = VideoParametersPresets.h540_169,
     this.deviceId,
+    this.effectsSdkRequired,
     this.maxFrameRate,
     this.processor,
   });
diff --git a/pubspec.lock b/pubspec.lock
index b39f0ae..2cd7406 100644
--- a/pubspec.lock
+++ b/pubspec.lock
@@ -141,10 +141,10 @@ packages:
     dependency: "direct main"
     description:
       name: dart_webrtc
-      sha256: "8565f1f1f412b8a6fd862f3a157560811e61eeeac26741c735a5d2ff409a0202"
+      sha256: "5b76fd85ac95d6f5dee3e7d7de8d4b51bfbec1dc73804647c6aebb52d6297116"
       url: "https://pub.dev"
     source: hosted
-    version: "1.5.3"
+    version: "1.5.3+hotfix.2"
   dbus:
     dependency: transitive
     description:
@@ -219,11 +219,10 @@ packages:
   flutter_webrtc:
     dependency: "direct main"
     description:
-      name: flutter_webrtc
-      sha256: "4f0d6e248f178e617f249b6a2f432b5981e3300c2896fc8d476fc2aa1f525547"
-      url: "https://pub.dev"
-    source: hosted
-    version: "0.13.1"
+      path: "../flutter-webrtc-patch"
+      relative: false
+    source: path
+    version: "0.14.0"
   glob:
     dependency: transitive
     description:
@@ -328,6 +327,14 @@ packages:
       url: "https://pub.dev"
     source: hosted
     version: "1.16.0"
+  mime_type:
+    dependency: "direct main"
+    description:
+      name: mime_type
+      sha256: d652b613e84dac1af28030a9fba82c0999be05b98163f9e18a0849c6e63838bb
+      url: "https://pub.dev"
+    source: hosted
+    version: "1.0.1"
   mockito:
     dependency: "direct dev"
     description:
@@ -353,7 +360,7 @@ packages:
     source: hosted
     version: "2.2.0"
   path:
-    dependency: transitive
+    dependency: "direct main"
     description:
       name: path
       sha256: "75cca69d1490965be98c73ceaea117e8a04dd21217b37b292c9ddbec0d955bc5"
@@ -593,10 +600,10 @@ packages:
     dependency: transitive
     description:
       name: webrtc_interface
-      sha256: e92afec11152a9ccb5c9f35482754edd99696e886ab6acaf90c06dd2d09f09eb
+      sha256: "86fe3afc81a08481dfb25cf14a5a94e27062ecef25544783f352c914e0bbc1ca"
       url: "https://pub.dev"
     source: hosted
-    version: "1.2.2+hotfix.1"
+    version: "1.2.2+hotfix.2"
   win32:
     dependency: transitive
     description:
diff --git a/pubspec.yaml b/pubspec.yaml
index 1f1a41e..d08a9ef 100644
--- a/pubspec.yaml
+++ b/pubspec.yaml
@@ -37,7 +37,8 @@ dependencies:
   uuid: ^4.5.1
   synchronized: ^3.0.0+3
   protobuf: ^3.0.0
-  flutter_webrtc: ^0.14.0
+  flutter_webrtc:
+    path: ../flutter-webrtc-patch
   device_info_plus: ^11.3.0
   dart_webrtc: ^1.5.3
   sdp_transform: ^0.3.2
